{
    "criteria": [
        {
            "criterion": "AllDocuments",
            "passed": true,
            "reason": "All documents pass."
        },
        {
            "criterion": "Domain",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "QuestionAnswerStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "QuestionAnswerStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "FullyStructured",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ListPrefix",
            "passed": false,
            "reason": "Found 0 list prefixes. (Min: 5)"
        },
        {
            "criterion": "ListPrefixV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesMinimalEmbed",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesSynonymsEmbed",
            "passed": true,
            "reason": "Text contains ['Here are some points on how to prevent this from happening and a few other optimization checks for archive pages. (0.196)']."
        },
        {
            "criterion": "ExamplesDiverseEmbed",
            "passed": true,
            "reason": "Text contains ['Here are some points on how to prevent this from happening and a few other optimization checks for archive pages. (0.150)', 'These can be removed using a plugin but if your blog uses these, it is a good practice to ensure that these URLs do not end up in a 404. (0.198)', 'For example, the category slug can have links to all your categories. (0.184)', \"If you are using the &lt!--nextpage--&gt tag on some of your larger posts to split them into multiple pages then it is a best measure to add the rel='next' and rel='prev' tags to these paginated pages. (0.199)\", 'As mentioned in the beginning, SEO plugins can do most of what has been listed here but it is always a good idea to check manually just to make sure that things are working as they are supposed to. (0.186)']."
        }
    ],
    "doc_id": "9687",
    "text": "Irrespective of if or not you use a SEO plugin, it is always a good idea to conduct some manual checks on your blog to ensure everything is working as it is supposed to. Faulty plugin settings, badly written custom code, badly coded themes can all cause SEO related issues which can easily go unnoticed and can hurt your blog's search engine rankings.\nHere are 27 standard checks that you can periodically conduct on your wordpress blog to ensure that your blog is free from SEO related issues.\nCheck to make sure that your blog's homepage has a descriptive title tag. The title tag should not just be SiteName.com but should include your most important keywords that aptly identify your blog.\nEven if you do not add meta description tags to your internal pages, it is important that you add one for your homepage. Just make sure that your meta description tag aptly summarizes what your blog is all about.\nTo achieve this without using a plugin, check out my article on adding meta description tags using wordpress custom fields.\nNote: If your homepage is paginated, restrict the meta tags to appear only on the first page and not on paginated pages as this can lead to meta tag duplication issues.\nIf your homepage has pagination, check to make sure that the paginated pages have the page number added to their title tags to avoid title tag duplication.\nIn addition to that, make sure that the rel=\"next\" and rel=\"prev\" tags are present. These tags help Google and other search engines understand that all paginated pages are part of the same sequence and hence are not to be indexed as separate pages. This is automatically taken care of if you are using the Yoast SEO plugin. If not, check out this article on how you can add these tags to your blog.\nYou can also consider adding a Robots NOINDEX tag to all paginated sub-pages. Make sure that you do not add the NOINDEX to the homepage and only add them to the paginated sub-pages.\nThese pages can cause duplicate content issues because they have little to no unique content and can run into numerous pages if your blog has many articles. Here are some points on how to prevent this from happening and a few other optimization checks for archive pages.\nIf possible add a category description to the main category archive page and display the author description on the main author archive page. This will ensure that the pages have some unique content. Restrict this description to the first (main) page only.\nIt is a good practice to add the rel=\"prev\" and rel=\"next\" meta tags to all archive pages that are paginated to indicate that they belong to the same sequence. If you want to know how to add these tags without using a plugin check out this article.\nCheck to make sure that the title tags on paginated archive pages display the page number. In the absence of a Page number, all pages of a particular paginated archive will have the exact same title tag giving rise to duplication issues.\nBaring the first page, add a Robots NOINDEX tag to all sub-pages of paginated archives. This will ensure that these sub-pages are not indexed by search engines. If you are not using a SEO plugin, check out this article on adding a NOINDEX tag to paginated wordpress pages.\nWordPress automatically adds the category, tag and author bases as shown in the image below.\nThese can be removed using a plugin but if your blog uses these, it is a good practice to ensure that these URLs do not end up in a 404.\nThis can easily by avoided by adding pages with the same slugs as the category, tag and author base.\nMake sure to populate these pages with proper related content. For example, the category slug can have links to all your categories.\nAs of now, I don't think there is a way to turn off these archives even if you don't intend on using them. You can either redirect these archive pages to the homepage of your blog or simply add a NOFOLLOW, INDEX to them which will instruct the search engine bots not to index them.\nIf you have a category named 'Healthy Eating', avoid having a tag with the exact same name as this can create duplicate title tags and content.\nIf you are running a single author blog it is likely that your homepage displays the same articles as your author archive page, especially if your homepage uses pagination. This can be seen as duplicate content by search engines. So to be on the safer side, consider blocking your author page from getting crawled using Robots.txt and also adding a NOFOLLOW, NOINDEX to the author archive pages.\nThere is not much you need to do when it comes to single posts expect if you are splitting single posts into multiple pages or if you are using wordpress comments broken into multiple comment pages.\nIf you are using the &lt!--nextpage--&gt tag on some of your larger posts to split them into multiple pages then it is a best measure to add the rel='next' and rel='prev' tags to these paginated pages. Check out this article on how you can add these tags using a simple function.\nIf you are using the built-in wordpress commenting system it is advisable not to break comments into multiple pages. But if you have too many comments on a page and absolutely need to break them into multiple pages, make sure to add page numbers to the title tags and even better a Robots NOINDEX, NOFOLLOW tag to the paginated comment pages.\nWordPress SEO starts with activating permalinks, so make sure that this feature is activated. You can have any kind of permalink structure, be it a simple structure with the site name followed by the URL or a slightly longer structure that contains year, month or category information.\nIrrespective of if or not you use the wordpress search feature, it is best to add a Robots NOINDEX tag to all auto generated search pages and 404 error pages. In addition to that, you can also consider adding a NOINDEX tag to low value pages like the contact, privacy and disclaimer page. More info in this article.\nMake sure to use a Robots.txt file to block search engine bots from crawling unwanted files and directories. Here is a sample Robots.txt file for wordpress that you can use to block the bots from accessing the wp-content/plugins/, wp-admin and wp-includes folder whilst allowing bots to access images in the wp-content uploads directory.\nOptimizing images involves compressing them so they load faster and adding descriptive alt and title tags.\nWordPress automatically adds alt tags to your images when you import them from the media library, but the auto-generated tags are often inadequate and contains an hyphenated string of text. It is best to manually edit the alt tags and include an apt description of the image. Similarly, you can also add a title tag to important images. The title tag is what gets displayed when a user hovers over the image.\nThe above wordpress generated filename can be manually edited to make it short and to the point by removing the stop words.\nNote: Do not edit filenames of articles that have already been written and published as this could lead to a temporary drop in rankings. Use this technique for the newer articles that you write.\nLinks to both external sources as well as internal sources need to be checked periodically to ensure they are not broken. This can easily be doing using a plugin like the broken link checker plugin.\nWordPress tends to create unique pages for media/image files that is uploaded to the media library. Note that this is different from the actual URL of the media file.\nOne way to avoid this issue is to redirect all image attachments back to the single post page. Another way is to add a Robots NOINDEX/FOLLOW tag to all image attachment pages.\nRead complete tutorial on wordpress attachment pages here.\nIf you do not want to use NoIndex/NoFollow method and want to redirect the image attachment pages to the main article page. You can do this by adding the following code within the head tags of your theme's header.php page.\nIf your blog is big and has hundreds of articles, consider adding a XML sitemap. Many SEO plugins have an option to add a XML sitemap. So if you are using a SEO plugin, check for that option. If not, you can use a standalone Sitemap plugin such as Google XML Sitemaps.\nCheck to see if your layout is fully responsive. Google's recent mobile friendly update ranks mobile friendly pages higher in comparison to non-responsive pages in mobile search results.\nYou can use Google's mobile friendly test to check if your blog's pages are fully responsive. If you think your blog is responsive and yet fails this test, then you could be blocking certain resources from being crawled. Check out this article for more info on this.\nPage loading speed is an important criteria in Google's ranking algorithm. Check your website using the PageSpeed Insights tool to see if your site is well optimized. Also check out this comprehensive article on how to speed up your wordpress page load times to know how you can optimize your blog by optimizing images, removing clutter and handling CSS and JS loading better.\nLast but not the least, regularly monitor your site using Google webmaster tools by conducting the following checks.\nHTML Improvements: The HTML Improvements section tells you if your site has any duplication issues. Go to Search Appearance > HTML Improvements and see if there are any pages listed.\nCrawl Errors: The crawl error section shows you all pages that returned a 404 or were unreachable on crawl. You can reach this section by going to Crawl > Crawl Errors.\nRobots.txt Tester: This section shows if there are any errors in your Robots.txt file. In addition to that, you can also check accessibility status of individual pages using the test tool located on this page. You can reach this section by going to Crawl > Robots.txt Teaster.\nMobile Usability: The mobile usability section lists pages on your blog that have usability errors. In other words, pages that are no fully responsive and the reason why they are not responsive. You can reach this section by going to Search Traffic > Mobile Usability.\nStructured Data: This section lists pages that have structured data markup errors. So if you are using structured data markup like Open Graph Tags then be sure to check this section. You can reach this section by going to Search Appearance > Structured Data.\nBlocked Resources: Lets you check if there are any images, JS or CSS files that you are blocking using Robots.txt and the various pages that use these resources. If you find any files listed here, consider unblocking those resources as long as they are not private resources. You can reach this section by going to Google Index > Blocked Resources.\nSecurity Issues: Lets you know if there are any security issues that Google has found on your blog.\nIf you are using the wordpress commenting system, make sure to monitor your comments and keep them clear of spam. This includes both spammy links and spammy content. Even if your links are nofollowed, presence of spammy links or spammy content can lower your search rankings.\nGoogle highly recommends adding using schema.org to mark-up your webpages. Schema.org can help search engines better understand different sections of your website which can help improve your search engine rankings. Many new wordpress themes already come with Schema.org mark-up, so you might want to check if your theme already has this.\nFor more information on what Schema.org is and how it can be used to mark-up your wordpress blog, check out this article.\nDowntimes can negatively impact your site's rankings which is why it is crucial to monitor it at regular intervals. There are many services like uptime robot that can help monitor your blog for free. These services will notify you as soon as your website goes down by sending you an email. If your blog experiences constant downtimes you might want to consider changing your host.\nThat pretty much covers everything you can do to make your wordpress blog search engine friendly. As mentioned in the beginning, SEO plugins can do most of what has been listed here but it is always a good idea to check manually just to make sure that things are working as they are supposed to.\nVery Much Detailed Article. it's Complete guide for new Blogger like me."
}