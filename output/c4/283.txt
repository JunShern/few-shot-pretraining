{
    "criteria": [
        {
            "criterion": "AllDocuments",
            "passed": true,
            "reason": "All documents pass."
        },
        {
            "criterion": "QuestionAnswerStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "FullyStructured",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ListPrefixV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesMinimalEmbed",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesSynonymsEmbed",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesDiverseEmbed",
            "passed": true,
            "reason": "Text contains ['These kinds of numbers are no problem in general \u2013 the webserver and database are easily capable of handling the load. (0.172)', 'Here you are thinking you will be producing great features and then these things come rumbling along at you. (0.186)']."
        }
    ],
    "doc_id": "283",
    "text": "I love Google \u2013 they send me stacks of traffic and make sites like Booko reach a far greater audience than I could effect on my own. Recently, however, Google\u2019s taken a bigger interest in Booko than usual. These kinds of numbers are no problem in general \u2013 the webserver and database are easily capable of handling the load.\nWhen this request comes in, Booko will check to see how old the prices are \u2013 if they\u2019re more than 24 hours old, Booko will attempt to update the prices. Booko used to load the prices into the browser via AJAX \u2013 so, as far as I can tell, Google wasn\u2019t even seeing the prices. Further, Booko has a queuing system in place for requests to look up prices, so when Google requests pages, this adds a book to the queue of books to be looked up. Google views books faster than Booko can grab the prices, so we end up with 100\u2019s of books scheduled for lookup, frustrating normal Booko users who see the problem as a page full of spinning wheels \u2013 wondering why Booko isn\u2019t giving them prices. Meanwhile, the price grabbers are hammering through hundreds of requests from Google, in turn, hammering all the sites Booko indexes. So, what to do?\nThese commands will drop all Google traffic.\nThe next step was to go to sign up for Google Webmaster Tools and reduce the page crawl rate.\nTo make Booko more Google friendly, the first code change was to have book pages rendered immediately with the available pricing (provided it\u2019s complete) and have updates to that pricing delivered via AJAX. Google now gets to see the entire page and should (hopefully) provide better indexing.\nThe second change was to create a second queue for price updates \u2013 the bulk queue. The price grabbers will first check for regular price update requests \u2013 meaning people will get their prices first. Requests by bulk users, such as Google, Yahoo & Bing, will be added to the bulk queue and looked up when there are no normal requests. In addition, I can restrict the number of price grabbers which will service the bulk queue.\nThis work has now opened up a new idea I\u2019ve been thinking about \u2013 pre-emptively grab the prices of the previous day or week\u2019s most popular titles. The idea would be to add these popular titles to the bulk queue during the quiet time between 03:00 and 06:00. That would mean that when people viewed the title later that day, they\u2019d be fresh.\nI\u2019ve just pushed these changes into the Booko site and with some luck, Google & Co will be happier, Booko users will be happier and I should be able to build new features with this ground work laid. Nice for a Sunday evening\u2019s work.\nIt is funny what you end up working on. Here you are thinking you will be producing great features and then these things come rumbling along at you. Good job getting the monster under control!\nTotally! It\u2019s it quickly went to the top of my list when Booko kept emailing me that it has 100\u2019s of books to grab prices for!\nI like the idea of your site.\nSurely the easiest solution to your problem here is simply adding a robots.txt file telling google not to index /isbn/* ?\nThat would drop this problem immediately.\nThat surely would be the most expedient solution to the problem \u2013 however, as much of my traffic is coming from Google, from searches for book titles, I want Google to see the book titles. I could have also prevented a view from Google initiating a price grab, but the bulk queue idea means I could do overnight loads of popular titles."
}