{
    "criteria": [
        {
            "criterion": "AllDocuments",
            "passed": true,
            "reason": "All documents pass."
        },
        {
            "criterion": "Domain",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "QuestionAnswerStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "QuestionAnswerStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "FullyStructured",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ListPrefix",
            "passed": false,
            "reason": "Found 0 list prefixes. (Min: 5)"
        },
        {
            "criterion": "ListPrefixV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesMinimalEmbed",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesSynonymsEmbed",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesDiverseEmbed",
            "passed": true,
            "reason": "Text contains ['(edit) Canticle for Leibowitz does make the point that the products of science easily get beyond human control and if some of us survive a nuclear disaster our descendents will probably end up creating another one a couple thousand years in the future. (0.189)']."
        }
    ],
    "doc_id": "265",
    "text": "Walter M. Miller, Jr. - Wikipedia, the free encyclopedia.\nInteresting but barely relevant to \"Spirituality\" or \"Singularity.\"\nBombing Monte Cassino, a monestary founded by Benedict in the seventh century (a mission totally irrelevant for the Allied victory in WWII) led to conversion to Catholicism, PTSD. and the writing of A Canticle for Leibowitz, a post-apocolyptic novel about science, religion, and politics, but not really relevant for what i want to say about spirituality and singularity.\nBradberry's Farenheit 451 might be more appropriate?.\n(edit) Canticle for Leibowitz does make the point that the products of science easily get beyond human control and if some of us survive a nuclear disaster our descendents will probably end up creating another one a couple thousand years in the future. This might provide all the possible negative effects of of a possible technological singularity without the help of superintelligent machines.\nDo you know anybody whose I.Q. is twenty points higher than your own? Can you tell a difference between you two that higher I.Q. might account for? Imagine an I.Q. 500 points (500 percent) or 5000 points bigher. Do we know enough about intelligence, or even about what intelligence is, to trust ourselves to create machines that can outsmart us? Would superintelligent machines be superservants, superscientists, supermystics, or supertyrants?\nWould human beings, or life itself, be considered obsolete, superfluous? How would i respond to such a situation, like Crazy Horse, Like St. Francis, like a maniac? Would it matter? (edit) Would the machines respect us as their creators, puny though we my be?"
}