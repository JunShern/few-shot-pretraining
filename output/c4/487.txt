{
    "criteria": [
        {
            "criterion": "AllDocuments",
            "passed": true,
            "reason": "All documents pass."
        },
        {
            "criterion": "Domain",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "QuestionAnswerStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "QuestionAnswerStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "FullyStructured",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ListPrefix",
            "passed": false,
            "reason": "Found 0 list prefixes. (Min: 5)"
        },
        {
            "criterion": "ListPrefixV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesMinimalEmbed",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesSynonymsEmbed",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesDiverseEmbed",
            "passed": true,
            "reason": "Text contains ['But I have noticed another reason that this often fails, and it is similar to point three (The calculation is way too complex or expensive) and that is because there are too many metrics in the measure. (0.193)', 'The ideal number in my experience is a singular focus on the one most important metric that the agency can have some direct influence over. (0.183)', 'For those wanting a more diversified range of metrics, three is ideal, depending on the size of the performance bonus prize. (0.186)']."
        }
    ],
    "doc_id": "487",
    "text": "How many KPIs are optimal to drive agency performance?\nThe concept of performance based remuneration or payment by results appears to me to be universally embraced. After all, according to the latest ANA Agency Compensation Trends Survey, 68% of marketers\u2019 arrangements have a performance or results based payment component. The problem is that it is often poorly executed.\nBut I have noticed another reason that this often fails, and it is similar to point three (The calculation is way too complex or expensive) and that is because there are too many metrics in the measure.\nExamples include: sales, traffic, profit, market share, volume growth, etc. These can be measured by the same criteria that the advertiser uses for their internal bonus systems.\nThe Agency often claims that business results may not be within their \u2018span of control\u2019 as many factors besides advertising can affect business outcomes.\nExamples include: product awareness, ad awareness measures, consumer measures, attitude ratings, persuasion, purchase intent, awards, brand equity, image, effectiveness awards, etc.\nThis kind of performance assessment is vulnerable to research technique, statistical anomalies and discussions of creative \u2018philosophy\u2019.\nRelates to the evaluation of agency functional areas: account services, creative and media in terms of: performance, service, relationship, cost efficiencies, etc.\nThis is highly subjective and may be affected by \u2018entertainment\u2019 on the upside and personality problems on the downside.\nThe right metrics are more important than the number. So lets deal with this first.\nWhat are the right type of metrics?\n1. Developing a list of metrics available to you.\nWe had a client who proposed investing almost quarter of a million dollars a year to buy data on a quarterly basis to measure and pay a performance bonus of less than $200,000. Poor investment.\n2. Rank the order of importance of the metrics to the various stakeholders.\nNot all stakeholders across an organisation have the same objectives (which explains the misalignment and lack of collaboration). It is important to align metrics to the valuable stakeholder groups. CFOs and CEOs will generally focus on financial metrics, while marketers will have marketing metrics as well and so on. Understanding these alignments is crucial.\n3. Evaluate the level of influence the agency has on the metric.\nOf course no-one can control everything, but marketing is about influence. Therefore it is important to understand the metrics the agency can influence and by how much. We had a retail client who wanted to measure the agency against sales, but we pointed out that the agency had more influence on foot-traffic through their store, which correlated closely with sales.\n4. Plot the importance against the level of influence of the agency.\nCreate a matrix with key stakeholder importance against agency influence. At the bottom will be those metrics that are least important to the key stakeholder \u2013 lets say agency relationship performance and in the top the metric of most significance to the CEO being the profitability. Across the matrix on the left will be those metrics that the agency can directly influence, being the relationship with the client and on the right would be the metric they can least directly impact like profitability of the company. And all the rest are somewhere in between.\n5. Select the most appropriate metrics for the situation.\nThis is a balancing act. It is not valuable to choose metrics the agency cannot directly impact just as it is not valuable choosing metrics that are not significant to the key stakeholders. But you can look for those metrics that the agency can influence and also correlate with the more significant eg. Store foot traffic and retail sales or brand health and market share etc.\nThe agency ends up focusing on a multitude of metrics and actually influencing none at all.\nOr they focus only on the ones they can directly influence, gambling on the fact this will maximise their returns.\nThe relative size of the bonus paid for each metric diminishes with the number of metrics being measured and so the influence of the bonus is also diminished.\nThe more metrics, the more measuring, the greater the complexity and cost and the less likely to drive focus and effort.\nThe ideal number in my experience is a singular focus on the one most important metric that the agency can have some direct influence over. For those wanting a more diversified range of metrics, three is ideal, depending on the size of the performance bonus prize.\nThere are two main reasons this process fails. The first is due to the marketer or procurement making the performance models horribly complex by trying to make them a surgical tool in supplier management. Largely they fail because they do not acknowledge the bluntness of the tool.\nThe second is the agency trying to mitigate risk by adding as many metrics as possible. Adding more subjective metrics into the mix can ensure that unlike empirical metrics which will range from 0 to the highest level, subjective metrics are inclined to inhabit a narrow range, usually above the midpoint range.\nBut entering into a performance bonus to mitigate risk, mitigates the reason for the performance measure in the first place. It is like an athlete wanting to add other metrics such as beauty, intelligence and like-ability as factors in determining the results of Olympic 100 metres athletics competition.\nCritical to success is a significant carrot, a clear and focused metric or metrics, that the agency can influence, and is significant to the key stakeholders within the organisation.\nHow are your performance metrics looking? Are they relevant? Are they complex? Are they focused?"
}