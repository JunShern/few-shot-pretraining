{
    "criteria": [
        {
            "criterion": "AllDocuments",
            "passed": true,
            "reason": "All documents pass."
        },
        {
            "criterion": "Domain",
            "passed": false,
            "reason": "Document source unavailable."
        },
        {
            "criterion": "QuestionAnswerStrings",
            "passed": true,
            "reason": "Text contains A:."
        },
        {
            "criterion": "QuestionAnswerStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "FullyStructured",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ListPrefix",
            "passed": false,
            "reason": "Found 0 list prefixes. (Min: 5)"
        },
        {
            "criterion": "ListPrefixV2",
            "passed": true,
            "reason": "Text contains ['1', '2', '3', '-', '1', '2', '-', '-', '-', '-']."
        }
    ],
    "doc_id": "5460",
    "text": "\nLLVM\u2019s garbage collection facilities and SBCL\u2019s generational GC - lispm\nhttps://medium.com/@MartinCracauer/llvms-garbage-collection-facilities-and-sbcl-s-generational-gc-a13eedfb1b31\n======\npcwalton\n> I hope I explained why \u201cone size fits all\u201d does not really do it in garbage\n> collection.\n\nGreat to see people acknowledge this. Garbage collection is full of tradeoffs;\nbe skeptical of any claims to the contrary.\n\nI also like the way the author emphasizes the importance of inline bump\nallocation in the nursery. In the fast path, allocation of memory doesn't need\nto be any more than 5 or 6 instructions. This speed advantage is huge, and GC\nschemes that throw it away need to have a _very_ good reason for doing so.\n\n~~~\nmaximilianburke\n> In the fast path, allocation of memory doesn't need to be any more than 5 or\n> 6 instructions. This speed advantage is huge, and GC schemes that throw it\n> away need to have a very good reason for doing so.\n\nI have some experience writing garbage collectors and with the situations I\nwas targeting the handful of instructions quickly fades when multiple threads\ncome into the equation.\n\n1\\. Using atomics for bumping the pointer had some luck but contended atomics\non the platforms I was targeting meant that the low-instruction-count\nallocation was still slow.\n\n2\\. Using locks (futex-style) was slow, as expected.\n\n3\\. The best results I found for my use case (precise garbage collector for a\nruntime targeting video game consoles) resulted in per-thread nursery-type\nallocation arenas, selected by TLS, with no locks in the fast-path. This was\nslower than the ideal single-threaded fast path because of the TLS overhead.\n\n~~~\npcwalton\nYeah, the canonical solution for multithreaded GC is the third option (TLABs).\nThe TLS overhead is annoying, but on some architectures you can get away with\nburning a register to save the TLS load. It might well be worth it on AArch64,\nwith its 32 GPRs...\n\n(TLABs are the recommended solution for multithreaded malloc implementations\nlike jemalloc and tcmalloc as well.)\n\n~~~\ncwzwarich\nAArch64 has a dedicated register (TPIDR_EL0) for TLS.\n\n~~~\npcwalton\nDidn't know that, thanks!\n\n------\neschew\nAt least two of the article's statements about LLVM are false. In particular:\n\n1) LLVM doesn't place any restrictions on how a language runtime allocates\nmemory.\n\n2) LLVM doesn't \"expect\" a stack map -- it provides infrastructure to compute\nthem if the front end wants to, but the front end is completely free to ignore\nthat infrastructure.\n\n~~~\nfao_\nAre those corrections to the incorrect statements, or the incorrect statements\nthemselves? It's not very clear, I'm sorry.\n\n~~~\nsinistersnare\nSo I wouldnt say that LLVM places restrictions, but I will say a little of my\nexperience doing LLVM + BoehmGC\n\nBoehmGC uses the stack for its root set (where it starts to find live memory).\nWith LLVM, you dont ever need to explicitly use the stack, you can use\nregisters for everything and make LLVM figure out if it should go on the stack\nor not. If you want to use Boehm with LLVM, you are forced to explicitly\nallocate everything on the stack, and not just on a register, so that Boehm is\nguaranteed to find the memory.\n\nSo I wouldnt say restriction, but definitely you need to think about how LLVM\noperates with the GC and other runtime components of your language.\n\n------\ntwoodfin\nI love the idea of a \u201cliberal\u201d GC that occasionally throws away bits of memory\nstill in use in the name of raw performance for restartable tasks.\n\n~~~\njohncolanduoni\nHow do you know when to restart the task? Or that your output isn\u2019t the\nproduct of an out of range memory access?\n\n~~~\neslaught\nYou unmap the memory when you free it so that it causes a segfault if you\naccess it, and then if a segfault occurs you know something went wrong.\n\n~~~\nlittlestymaar\n> so that it causes a segfault if you access it\n\nNo, this is UB. It can cause a segfault, but it can also allow _bad things_ \u2122\nto happen.\n\n~~~\nbarrkel\nLet's be clear on the difference between C and C++ undefined behaviour, and\nmachine behaviour that GCs and runtimes can use for implementation.\n\nIt is not unusual to rely on triggering a hardware exception in runtimes and\nGCs, up to and including segfaults. For example, a check for safepoint might\nbe implemented by attempting to read a particular address. When the GC needs\nto stop the world, it could change the protection bits on the page that\ncontains that address. This technique minimizes the amount of code in the\nsafepoint test and doesn't require any branching logic.\n\nSee e.g. [https://stackoverflow.com/questions/46394575/safepoints-\nin-j...](https://stackoverflow.com/questions/46394575/safepoints-in-jvm)\n\nAnother technique: a runtime can support dynamic growth of the stack by\nkeeping an unmapped or protected page at the limit, and extending it when hit.\nThis is how stacks work on Windows, and it relies on help from codegen:\ncompilers targeting Windows need to generate code that performs a loop\ntouching every page in its stack frame allocation one at a time in allocation\norder, if the stack frame is larger than the page size.\n\nSee e.g. [https://geidav.wordpress.com/tag/stack-\nprobing/](https://geidav.wordpress.com/tag/stack-probing/)\n\n------\nmasklinn\n> Another example where you want to keep for-GC bookkeeping overhead in\n> mainline code low is if you can \u201cGC-by-fork\u201d, which is basically throwing\n> away processes as they would need to GC\n\nThat's one of the common options in Erlang/Elixir: spawn a worker process for\neach task with a `min_heap_size` high enough that most workloads would not\ntrigger a collection (the default is fairly low), let it die after it's\nhandled the request. More complex/memory intensive tasks will fall through to\nnormal GC-ing behaviour once they breach the `min_heap_size` limit.\n\n------\nTarean\n> it is copying, however other passes that just punch holes into existing\n> cards (to wipe pointers that are not pointed to anymore without moving a lot\n> of memory) have and will be added\n\nI have a basic understanding about card tables and promotion but couldn't find\nanything about hole punching. Pretty sure I have heard the term before and was\njust as confused, could someone point me into the right direction for this?\n\nFrom context I'd guess that it means the gc doesn't copy unless x% of the\nblock is unused?\n\n~~~\ncracauer\nI use the \"punch holes\" phrase in the following situation: \\- GC is\ncopying/compacting \\- GC is at least slightly conservative \\- allocation is\nfast/inline/increment-only \\- that leaves you in a situation where you cannot\nmove/compact some part of the heap\n\nYou cannot move the possibly (conservatively) pointed to thing because you\ncannot adjust the pointer to it (because it might be a non-pointer thing such\nas an integer.\n\nNow you have some GC unit worth of space occupied by one unmovable object,\notherwise it's empty space backed by physical pages. What do you do with the\nrest of the space? In a C/malloc scheme you are aware of such holes and fill\nthem from new allocations. When you have a fast allocation scheme not\ninvolving complex code to find holes you will keep these \"hole\" as long as the\nconservative-pointer looking thing exists. You do wipe all the other\npointerish things in that GC area, though, so that they don't hold down\nadditional space. Still, now you \"waste\" a whole GC card worth of physical RAM\non a single object, the tradeoff being that you do not want to move to an\nallocation scheme that spends time thinking about fragmentation.\n\nYou could use the empty space in those GC cards as a target for the next\nmoving GC, however that has drawbacks as you know continue to have to special-\ntreat such regular objects co-located with possibly conservatively pointed to\nobjects.\n\nIf there is a better term than \"punching holes\" for this I would be\ninterested.\n\nETA: now that I think about it, you could give back all physical pages in that\nGC card that do not contain the held down object. This assumes that GC card\nsize is more than one VM page.\n\n------\ncracauer\n(author here) Just wanted to say that I have seen the comments and will\naddress them when I have a chance. My post turned out to be a lot more popular\nthan I anticipated and I was busy yesterday and today. I wrote most of this in\nsummer 2017, so given the popularity I will also provide a refresh with\ntoday's state of LLVM.\n\nPlease keep corrections to my post coming, the time to determine and influence\nGC design restrictions in LLVM is now. Before a popular GCed language comes\nalong and then tramples whatever its current GC happens to be into the status\nquo.\n\n"
}