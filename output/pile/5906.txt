{
    "criteria": [
        {
            "criterion": "AllDocuments",
            "passed": true,
            "reason": "All documents pass."
        },
        {
            "criterion": "QuestionAnswerStringsV2",
            "passed": true,
            "reason": "Text contains ['Q:', 'A:']."
        },
        {
            "criterion": "FullyStructured",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ListPrefixV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesMinimalEmbed",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesSynonymsEmbed",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesDiverseEmbed",
            "passed": false,
            "reason": "Does not meet criterion."
        }
    ],
    "doc_id": "5906",
    "text": "Q:\n\nPython run_in_executor and forget?\n\nHow can I set a blocking function to be run in a executor, in a way that the result doesn't matter, so the main thread shouldn't wait or be slowed by it.\nTo be honest I'm not sure if this is even the right solution for it, all I want is to have some type of processing queue separated from the main process so that it doesn't block the server application from returning requests, as this type of web server runs one worker for many requests.\nPreferably I would like to keep away from solutions like Celery, but if that's the most optimal I would be willing to learn it.\nThe context here is a async web server that generates pdf files with large images.\napp = Sanic()\n#App \"global\" worker\nexecutor = ProcessPoolExecutor(max_workers=5)\n\napp.route('/')\nasync def getPdf(request):\n  asyncio.create_task(renderPdfsInExecutor(request.json))\n  #This should be returned \"instantly\" regardless of pdf generation time\n  return response.text('Pdf being generated, it will be sent to your email when done')\n\nasync def renderPdfsInExecutor(json):\n  asyncio.get_running_loop.run_in_executor(executor, syncRenderPdfs, json)\n\ndef syncRenderPdfs(json)\n  #Some PDF Library that downloads images synchronously\n  pdfs = somePdfLibrary.generatePdfsFromJson(json)\n  sendToDefaultMail(pdfs)\n\nThe above code gives the error (Yes, it is running as admin) : \nPermissionError [WinError 5] Access denied\nFuture exception was never retrieved\n\nBonus question: Do I gain anything by running a asyncio loop inside the executor? So that if it is handling several PDF requests at once it will distribute the processing between them. If yes, how do I do it?\n\nA:\n\nOk, so first of all there is a misunderstanding. This \nasync def getPdf(request):\n    asyncio.create_task(renderPdfsInExecutor(request.json))\n    ...\n\nasync def renderPdfsInExecutor(json):\n    asyncio.get_running_loop.run_in_executor(executor, syncRenderPdfs, json)\n\nis redundant. It is enough to do\nasync def getPdf(request):\n    asyncio.get_running_loop.run_in_executor(executor, syncRenderPdfs, request.json)\n    ...\n\nor (since you don't want to await) even better\nasync def getPdf(request):\n    executor.submit(syncRenderPdfs, request.json)\n    ...\n\nNow the problem you get is because syncRenderPdfs throws PermissionError. It is not handled so Python warns you \"Hey, some background code threw an error. But the code is not owned by anyone so what the heck?\". That's why you get Future exception was never retrieved. You have a problem with the pdf library itself, not with asyncio. Once you fix that inner problem it is also a good idea to be safe:\ndef syncRenderPdfs(json)\n    try:\n        #Some PDF Library that downloads images synchronously\n        pdfs = somePdfLibrary.generatePdfsFromJson(json)\n        sendToDefaultMail(pdfs)\n    except Exception:\n        logger.exception('Something went wrong')  # or whatever\n\nYour \"permission denied\" issue is a whole different thing and you should debug it and/or post a separate question for that.\nAs for the final question: yes, executor will queue and evenly distribute tasks between workers.\nEDIT: As we've talked in comments the actual problem might be with the Windows environment you work on. Or more precisely with the ProcessPoolExecutor, i.e. spawning processes may change permissions. I advice using ThreadPoolExecutor, assuming it works fine on the platform.\n\n"
}