{
    "criteria": [
        {
            "criterion": "AllDocuments",
            "passed": true,
            "reason": "All documents pass."
        },
        {
            "criterion": "Domain",
            "passed": false,
            "reason": "Document source unavailable."
        },
        {
            "criterion": "QuestionAnswerStrings",
            "passed": true,
            "reason": "Text contains Q:."
        },
        {
            "criterion": "QuestionAnswerStringsV2",
            "passed": true,
            "reason": "Text contains ['A:', 'A:', 'Q:', 'A:', 'A:']."
        },
        {
            "criterion": "FullyStructured",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ListPrefix",
            "passed": false,
            "reason": "Found 0 list prefixes. (Min: 5)"
        },
        {
            "criterion": "ListPrefixV2",
            "passed": true,
            "reason": "Text contains ['-', '-', '-', '*', '*', '1', '0', '0', '1', '0', '1', '-', '-', '1', '0', '0', '1', '*', '*', '1']."
        },
        {
            "criterion": "ExamplesMinimalEmbed",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesSynonymsEmbed",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesDiverseEmbed",
            "passed": true,
            "reason": "Text contains ['Note, in the above theorems, that we do not require that the direction of the line be included in $S$! (0.185)']."
        }
    ],
    "doc_id": "798",
    "text": "---\nabstract: |\n    Let $n$ and $p$ be non-negative integers with $n \\geq p$, and $S$ be a linear subspace of the space of all $n$ by $p$ matrices with entries in a field $\\K$. A classical theorem of Flanders states that $S$ contains a matrix with rank $p$ whenever ${\\operatorname{codim}}S <n$.\n\n    In this article, we prove the following related result: if ${\\operatorname{codim}}S<n-1$, then, for any non-zero $n$ by $p$ matrix $N$ with rank less than $p$, there exists a line that is directed by $N$, has a common point with $S$ and contains only rank $p$ matrices.\nauthor:\n- 'Cl\u00e9ment de Seguins Pazzis[^1] [^2]'\ntitle: Lines of full rank matrices in large subspaces\n---\n\n*AMS Classification:* 15A03, 15A30.\n\n*Keywords:* Full rank, Matrices, Dimension, Flanders\u2019s theorem.\n\nIntroduction\n============\n\nThroughout the article, $\\K$ denotes an arbitrary field. Let $n$ and $p$ be non-negative integers. We denote by ${\\operatorname{M}}_{n,p}(\\K)$ the space of all $n$ by $p$ matrices with entries in $\\K$. In particular, we set ${\\operatorname{M}}_n(\\K):={\\operatorname{M}}_{n,n}(\\K)$ and we denote by ${\\operatorname{GL}}_n(\\K)$ its group of units. We denote by $E_{i,j}$ the matrix of ${\\operatorname{M}}_{n,p}(\\K)$ with zero entries everywhere except at the $(i,j)$-spot where the entry equals $1$.\n\nIn a landmark article [@Flanders], Flanders proved the following classical result:\n\nLet $n,p,r$ be non-negative integers such that $n \\geq p \\geq r$. Let $S$ be a linear subspace of ${\\operatorname{M}}_{n,p}(\\K)$ in which every matrix has rank less than or equal to $r$.\n\nThen, $\\dim S \\leq nr$.\n\nThe upper-bound $nr$ is optimal, as shown by the example of the space of all matrices with zero entries in the last $p-r$ columns. Before Flanders, Dieudonn\u00e9 [@Dieudonne] had already studied spaces of singular square matrices and obtained the special case $n=p$ and $r=n-1$ in the above theorem. Flanders actually had to assume that $\\# \\K>r$ due to his use of polynomials. This provision was lifted by Meshulam [@Meshulam] (for more recent proofs, see [@affpres; @dSPFlandersskew]).\n\nHere is a reformulation of Flanders\u2019s theorem: if $n \\geq p$, a linear subspace $S$ of ${\\operatorname{M}}_{n,p}(\\K)$ such that $\\dim S>nr$ must contain a matrix with rank greater than $r$. In this work, we shall be concerned with not only finding one such matrix, but a whole line of matrices with large rank. Better, we want to control the direction of such a line.\n\nBefore we formulate the problem, some basic considerations are necessary. Let $N \\in {\\operatorname{M}}_n(\\K) {\\smallsetminus}\\{0\\}$. If $N$ is invertible and $\\K$ is algebraically closed, then every line directed by $N$ must contain a singular matrix: indeed, for all $A \\in {\\operatorname{M}}_n(\\K)$, we can write $\\forall \\lambda \\in \\K, \\; \\det(A-\\lambda N)=(-1)^n (\\det N)\\, p(\\lambda)$ where $p$ denotes the characteristic polynomial of $N^{-1}A$, and $p$ must have a root.\n\nConversely, every non-zero matrix with non-full rank directs a line of full rank matrices, as stated in the following lemma.\n\n\\[fullspacelemma\\] Let $n \\geq p$ be non-negative integers and $N \\in {\\operatorname{M}}_{n,p}(\\K)$ be such that ${\\operatorname{rk}}N<p$. Then, there exists $A \\in {\\operatorname{M}}_{n,p}(\\K)$ such that every matrix of $A+\\K N$ has rank $p$.\n\nSet $r:={\\operatorname{rk}}N$. Without loss of generality, we can assume that $$N=\\begin{bmatrix}\nI_r & [0]_{r \\times (p-r)} \\\\\n[0]_{(n-r) \\times r} & [0]_{(n-r) \\times (p-r)}\n\\end{bmatrix}.$$ If $n>p$, one checks that $A:=\\underset{j=1}{\\overset{p}{\\sum}} E_{j+1,j}$ has the requested property.\\\nIf $n=p$ one checks that the matrix $A:=E_{1,n}+\\underset{j=1}{\\overset{n-1}{\\sum}} E_{j+1,j}$ has the requested property.\n\nNow, here is our problem for square matrices: given a linear subspace $S$ of ${\\operatorname{M}}_n(\\K)$ and a non-zero *singular* matrix $N \\in S$, under what conditions on $\\dim S$ can we guarantee that there exists $A \\in S$ for which every matrix of $A+\\K N$ is invertible? More generally, if $n \\geq p$, and given a linear subspace $S$ of ${\\operatorname{M}}_{n,p}(\\K)$ and a non-zero matrix $N \\in S$ with rank less than $p$, under what conditions on $\\dim S$ can we guarantee that there exists $A \\in S$ for which every matrix of $A+\\K N$ has rank $p$?\n\nThese questions are motivated by potential applications to the structure of spaces of bounded rank matrices over small finite fields. The following theorem, which is the main point of the present article, gives a full answer to them.\n\n\\[rectangulartheorem\\] Let $n \\geq p \\geq 2$ be integers. Let $S$ be a linear subspace of ${\\operatorname{M}}_{n,p}(\\K)$ with ${\\operatorname{codim}}S\\leq n-2$, and let $N \\in {\\operatorname{M}}_{n,p}(\\K)$ be such that ${\\operatorname{rk}}N<p$. Then, there exists $A \\in S$ such that every matrix of $A+\\K N$ has rank $p$.\n\nHere is a reformulation in terms of operator spaces:\n\n\\[operatortheorem\\] Let $U$ and $V$ be finite-dimensional vector spaces with $\\dim U \\leq \\dim V$. Let $S$ be a linear subspace of $\\calL(U,V)$ such that ${\\operatorname{codim}}S \\leq \\dim V-2$, and $t \\in \\calL(U,V)$ be a non-injective operator. Then, there exists $a \\in S$ such that every operator in $a+\\K t$ is injective.\n\nNote, in the above theorems, that we do not require that the direction of the line be included in $S$!\n\nLet us immediately show that the upper-bound $n-2$ from Theorem \\[rectangulartheorem\\] is optimal. Consider the matrix $N:=\\begin{bmatrix}\nI_{p-1} & [0]_{(p-1) \\times 1} \\\\\n[0]_{(n-p+1) \\times (p-1)} & [0]_{(n-p+1) \\times 1}\n\\end{bmatrix}$, and the space $S$ of all matrices of the form $$\\begin{bmatrix}\n? & [?]_{1 \\times (p-1)} \\\\\n[0]_{(n-1)\\times 1} & [?]_{(n-1) \\times (p-1)}\n\\end{bmatrix}.$$ Then, for all $A \\in S$, some matrix in $A+\\K N$ has zero as its first column, and hence not every matrix in $A+\\K N$ has rank $p$. Yet, ${\\operatorname{rk}}N<p$ and ${\\operatorname{codim}}S=n-1$.\n\nTheorem \\[rectangulartheorem\\] will be proved in three steps. In the first step, we shall consider the case of square matrices with ${\\operatorname{rk}}N=n-1$. The result actually deals with affine subspaces instead of just linear subspaces.\n\n\\[penciltheorem\\] Let $n$ be a non-negative integer. Let $N$ be a rank $n-1$ matrix of ${\\operatorname{M}}_n(\\K)$. Let $\\calS$ be an affine subspace of ${\\operatorname{M}}_n(\\K)$ such that ${\\operatorname{codim}}\\calS \\leq n-2$. Assume that at least one matrix of $\\calS$ maps ${\\operatorname{Ker}}N$ into ${\\operatorname{Im}}N$. Then, there exists $A \\in \\calS$ such that every matrix of $A+\\K N$ is invertible.\n\nAssume that $\\K$ is algebraically closed. Then, the condition that some matrix of $\\calS$ maps ${\\operatorname{Ker}}N$ into ${\\operatorname{Im}}N$ is unavoidable in Theorem \\[penciltheorem\\]. Consider indeed the matrix $N:=\\begin{bmatrix}\nI_{n-1} & [0]_{(n-1) \\times 1} \\\\\n[0]_{1 \\times (n-1)} & 0\n\\end{bmatrix}$ and the affine hyperplane $\\calS$ of all matrices of ${\\operatorname{M}}_n(\\K)$ with entry $1$ at the $(n,n)$-spot. For all $A \\in S$, the polynomial $\\det(A+tN)$ reads $t^{n-1}+\\underset{k=0}{\\overset{n-2}{\\sum}} b_k t^k$, and hence it is non-constant whenever $n\\geq 2$, which yields that $A+\\K N$ contains a singular matrix.\n\nIf $\\# \\K>2$, the proof of Theorem \\[penciltheorem\\] will actually demonstrate that there exists a matrix $A \\in \\calS$ such that the (formal) polynomial $\\det(A+tN)$ is constant and non-zero. As ${\\operatorname{rk}}N=n-1$, this can be restated in terms of matrix pencils as saying that the matrix pencil $A+tN$ is equivalent to the pencil $I_n+t J$, where $J$ is the Jordan matrix $(\\delta_{i,j-1})_{1 \\leq i,j \\leq n}$.\n\nIf $\\# \\K=2$, this result fails for $n=3$: one considers the space $\\calS$ of all matrices of the form $$\\begin{bmatrix}\n? & ? & a \\\\\n? & ? & ? \\\\\n? & a+1 & ?\n\\end{bmatrix} \\quad \\text{with $a \\in \\K$},$$ and the matrix $$N:=\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 0\n\\end{bmatrix}.$$ One sees that $\\calS$ has codimension $1$ in ${\\operatorname{M}}_3(\\K)$. Let $M=\\begin{bmatrix}\nA & C \\\\\nB & d\n\\end{bmatrix}\\in \\calS$, with $A \\in {\\operatorname{M}}_2(\\K)$, $B \\in {\\operatorname{M}}_{1,2}(\\K)$, $C \\in \\K^2$ and $d \\in \\K$. We have $$\\begin{aligned}\n\\det(M+tN)& = d \\det(A+tI_2)-B (A+t I_2)^\\ad C \\\\\n& =d \\det(A+tI_2)+B (A^\\ad+t I_2) C \\\\\n& =d \\det(A+tI_2)+t BC+B A^\\ad C,\\end{aligned}$$ where $A^\\ad$ denotes the transpose of the matrix of cofactors of $A$. Assume that the polynomial $\\det(M+tN)$ is constant. As $\\det(A+t I_2)$ has degree $2$, we successively obtain $d=0$ and $BC=0$. From the definition of $\\calS$, it follows that $B=0$ or $C=0$, and hence $\\det(M+tN)=0$.\n\nFinally, by checking the proof of Theorem \\[penciltheorem\\], one can prove that, if $\\# \\K=2$, if ${\\operatorname{codim}}\\calS \\leq n-3$ and some matrix of $\\calS$ maps ${\\operatorname{Ker}}N$ into ${\\operatorname{Im}}N$, then $\\det(A+tN)$ is constant and non-zero for some $A$ in $\\calS$. We suspect that this result still holds, provided that $n>3$, under the weaker assumption that ${\\operatorname{codim}}\\calS \\leq n-2$.\n\nIn Section \\[pencilproofsection\\], Theorem \\[penciltheorem\\] will be proved by induction over $n$. In the next section, we shall extend it as follows, by considering an arbitrary singular matrix $N$.\n\n\\[squaretheorem\\] Let $n$ be a non-negative integer. Let $N$ be a singular matrix of ${\\operatorname{M}}_n(\\K)$. Let $\\calS$ be an affine subspace of ${\\operatorname{M}}_n(\\K)$ such that ${\\operatorname{codim}}\\calS \\leq n-2$. Assume that there exists $M \\in \\calS$ such that the operator $X \\in {\\operatorname{Ker}}N \\mapsto \\overline{MX} \\in \\K^n/{\\operatorname{Im}}N$ is non-injective. Then, there exists $A \\in \\calS$ such that every matrix of $A+\\K N$ is invertible.\n\nAgain, this result will be proved by induction over $n$.\n\nIn the last step, by far the easiest one, we shall derive Theorem \\[rectangulartheorem\\] from Theorem \\[squaretheorem\\] (see Section \\[conclusionsection\\]).\n\nThe remaining open problem is the generalization of the above results to arbitrary ranks: given non-negative integers $n,p,r$ such that $n \\geq p \\geq r$, what is the smallest integer $d$ for which there exists a matrix $N \\in {\\operatorname{M}}_{n,p}(\\K)$ with rank less than $r$ and a linear subspace $S$ of ${\\operatorname{M}}_{n,p}(\\K)$ with codimension $d$ that contains no element $A$ for which all the matrices of $A+\\K N$ have rank greater than or equal to $r$? At the moment, we do not have a reasonable conjecture to suggest.\n\nProof of Theorem \\[penciltheorem\\] {#pencilproofsection}\n==================================\n\nThe proof of Theorem \\[penciltheorem\\] will be performed by induction over $n$, using several steps. If $n\\leq 1$ then the result is vacuous. If $n=2$, it is given by Lemma \\[fullspacelemma\\]. Assume now that $n \\geq 3$. We use a *reductio ad absurdum*, by assuming that there is no matrix $A \\in \\calS$ such that every matrix of $A+\\K N$ is invertible.\n\nWithout loss of generality, we can assume that $$N=\\begin{bmatrix}\nI_{n-1} & [0]_{(n-1) \\times 1} \\\\\n[0]_{1 \\times (n-1)} & 0\n\\end{bmatrix}.$$ Then, we can split every matrix $M$ of ${\\operatorname{span}}(\\calS)$ up as $$M=\\begin{bmatrix}\nA(M) & C(M) \\\\\nL(M) & d(M)\n\\end{bmatrix}$$ with $A(M) \\in {\\operatorname{M}}_{n-1}(\\K)$, $L(M) \\in {\\operatorname{M}}_{1,n-1}(\\K)$, $C(M) \\in \\K^{n-1}$ and $d(M) \\in \\K$. In $\\calS$, we have the affine subspace $$\\calV:=\\bigl\\{M \\in \\calS : \\; d(M)=0\\bigr\\}$$ with codimension at most $1$ (it is non-empty because we have assumed that at least one matrix of $\\calS$ maps ${\\operatorname{Ker}}N$ into ${\\operatorname{Im}}N$). We denote by $V$ the translation vector space of $\\calV$. In $V$, we have two specific linear subspaces $$T:=\\{M \\in V : \\; L(M)=0 \\; \\text{and}\\; C(M)=0\\}$$ and $$U:=\\{M \\in V : \\; C(M)=0\\}.$$ By the rank theorem, we have $$\\label{ranktheorem}\n\\dim A(T)+\\dim L(U)+\\dim C(\\calV)=\\dim \\calV.$$ In particular, since $\\dim \\calV > n(n-1)$ and $\\dim A(T) \\leq (n-1)^2$ we find $$\\label{dimC+dimL}\n\\dim C(\\calV)+\\dim L(U)>n-1.$$ Given $X \\in \\K^{n-1} {\\smallsetminus}\\{0\\}$, we denote by $A(T)_X$ the linear subspace of $A(T)$ consisting of the matrices with column space included in $\\K X$. The bilinear form $$b : (Y,X) \\in {\\operatorname{M}}_{1,n-1}(\\K) \\times \\K^{n-1} \\mapsto YX$$ is non-degenerate on both sides, and in the rest of the proof we shall consider orthogonality with respect to it. Note in particular that yields $C(\\calV) {\\smallsetminus}L(U)^\\bot \\neq \\emptyset$.\n\nNote that, for all $P \\in {\\operatorname{GL}}_{n-1}(\\K)$, neither the previous assumptions nor the conclusion are affected in replacing $\\calS$ with $Q \\calS Q^{-1}$ where $Q:=P \\oplus I_1$. In this transformation the spaces $L(U)$ and $C(\\calV)$ are respectively replaced with $L(U)P^{-1}$ and $P C(\\calV)$, whereas $b(YP^{-1},PX)=b(Y,X)$ for all $(Y,X) \\in {\\operatorname{M}}_{1,n-1}(\\K) \\times \\K^{n-1}$.\n\n\\[claim1\\] For all $X \\in C(\\calV) {\\smallsetminus}L(U)^\\bot$, there exists $M \\in \\calV$ such that $C(M)=X$ and $L(M)C(M)=0$.\n\nLet $X \\in C(\\calV) {\\smallsetminus}L(U)^\\bot$. We can find $(M_1,M_0) \\in \\calV\\times U$ such that $C(M_1)=X$ and $L(M_0)X \\neq 0$. For all $\\lambda \\in \\K$, we see that $C(M_1+\\lambda M_0)=X$ and $$L(M_1+\\lambda M_0)C(M_1+\\lambda M_0)=L(M_1)X+\\lambda L(M_0)X,$$ and hence for a well-chosen $\\lambda$ we find $L(M_1+\\lambda M_0)C(M_1+\\lambda M_0)=0$. This proves our claim.\n\n\\[claim2\\] For all $X \\in C(\\calV) {\\smallsetminus}L(U)^\\bot$, one has $$\\label{diminequality1}\n\\dim C(\\calV)+\\dim A(T)_X \\geq 2n-3.$$\n\nWe lose no generality in assuming that $X=\\begin{bmatrix}\n1 \\\\\n[0]_{(n-2) \\times 1}\n\\end{bmatrix}$. Denote by $\\calV'$ the affine subspace of $\\calV$ consisting of the matrices $M \\in \\calV$ such that $C(M)=X$. Every matrix $M \\in \\calV'$ splits up as $$M=\\begin{bmatrix}\n[?]_{1 \\times (n-1)} & 1 \\\\\nK(M) & [0]_{(n-1) \\times 1}\n\\end{bmatrix}$$ with $$K(M)=\\begin{bmatrix}\n[?]_{(n-2) \\times 1} & [?]_{(n-2) \\times (n-2)} \\\\\n? & [?]_{1 \\times (n-2)}\n\\end{bmatrix}\\in {\\operatorname{M}}_{n-1}(\\K).$$ Likewise, we write $$N=\\begin{bmatrix}\n[?]_{1 \\times (n-1)} & 0 \\\\\nN' & [0]_{(n-1) \\times 1}\n\\end{bmatrix}$$ with $$N'=\\begin{bmatrix}\n[0]_{(n-2) \\times 1} & I_{n-2} \\\\\n0 & [0]_{1 \\times (n-2)}\n\\end{bmatrix}.$$ By Claim \\[claim1\\], there exists $M \\in \\calV$ such that $C(M)=X$ and $L(M)X=0$, and hence $K(M)$ maps ${\\operatorname{Ker}}N'$ into ${\\operatorname{Im}}N'$. Moreover, $N'$ has rank $n-2$. Thus, if ${\\operatorname{codim}}K(\\calV') \\leq n-3$, then by induction we find a matrix $M \\in \\calV'$ such that $\\det (K(M)+tN') \\neq 0$ for all $t \\in \\K$; by developing the determinant along the last column, it would follow that $$\\forall t \\in \\K, \\; \\det(M+tN)=(-1)^{n+1} \\det(K(M)+tN')\\in \\K {\\smallsetminus}\\{0\\}.$$ This would contradict our assumptions. Therefore, ${\\operatorname{codim}}K(\\calV') \\geq n-2$.\n\nHowever, by the rank theorem, we see that $${\\operatorname{codim}}K(\\calV')= {\\operatorname{codim}}\\calV+\\bigl(\\dim C(\\calV)-(n-1))+\\bigl(\\dim A(T)_X-(n-1)\\bigr).$$ Thus, as our assumptions yield that ${\\operatorname{codim}}\\calV \\leq n-1$, we obtain claimed inequality .\n\nIt follows in particular that $$\\label{minorCS}\n\\dim C(\\calV) \\geq n-2.$$\n\nOne has $A(T)\\subsetneq {\\operatorname{M}}_{n-1}(\\K)$.\n\nAssume on the contrary that $A(T)={\\operatorname{M}}_{n-1}(\\K)$.\n\nFirst, assume further that there exists $M \\in \\calV$ such that $L(M) \\neq 0$, $C(M) \\neq 0$ and $L(M)C(M)=0$. As $A(T)={\\operatorname{M}}_{n-1}(\\K)$, we can assume, without loss of generality, that $$L(M)=\\begin{bmatrix}\n[0]_{1 \\times (n-2)} & 1\n\\end{bmatrix}, \\; C(M)=\\begin{bmatrix}\n1 \\\\\n[0]_{(n-2) \\times 1}\n\\end{bmatrix}\\; \\text{and} \\;\nA(M)=\\begin{bmatrix}\n[0]_{1 \\times (n-2)} & 0 \\\\\nI_{n-2} & [0]_{(n-2) \\times 1}\n\\end{bmatrix}.$$ Then, it is easily checked that $\\det(M+t N)=(-1)^{n+1}$, contradicting our basic assumptions on $\\calV$.\n\nTherefore, $$\\label{keyimp}\n\\forall M \\in \\calV, \\; L(M)C(M)=0\n\\Rightarrow (L(M)=0 \\; \\text{or}\\; C(M)=0).$$ Choose $X \\in C(\\calV) {\\smallsetminus}L(U)^\\bot$. We know from Claim \\[claim1\\] that there exists $M_1 \\in \\calV$ such that $C(M_1)=X$ and $L(M_1)X=0$. Let $M_2 \\in U$ be such that $L(M_2) \\bot X$. Then, $C(M_1+M_2)=X$ and $L(M_1+M_2)=L(M_1)+L(M_2)$ is orthogonal to $X$. It follows from that $L(M_1+M_2)=0$ and $L(M_1)=0$, whence $L(M_2)=0$. Therefore $L(U)\\cap  \\{X\\}^\\bot=\\{0\\}$, whence $\\dim L(U)\\leq 1$. By inequality , we deduce that $C(\\calV)=\\K^{n-1}$ and $\\dim L(U)=1$.\n\nFrom there, we split the discussion into two (non-disjoint) cases.\n\n-   **Case 1: $\\# \\K>2$.**\\\n    Let $M \\in \\calV$ be such that $C(M)\\not\\in L(U)^\\bot$. We can choose $M_0 \\in U$ such that $L(M_0)C(M) \\neq 0$. Then, for all $\\lambda \\in \\K$, we have $C(M+\\lambda M_0)=C(M)$ and $L(M+\\lambda M_0) C(M+\\lambda M_0)=L(M)C(M)+\\lambda L(M_0)C(M)$; we can then choose $\\lambda \\in \\K$ such that $L(M+\\lambda M_0) C(M+\\lambda M_0)=0$, leading, by , to $L(M+\\lambda M_0)=0$, and hence $L(M)=L(-\\lambda M_0) \\in L(U)$. Hence, we have shown that $L(M) \\in L(U)$ for all $M \\in \\calV$ such that $C(M)\\not\\in L(U)^\\bot$.\n\n    Yet, as $L(U)^\\bot$ is a proper affine subspace of $\\K^{n-1}$, its complementary subset in $\\K^{n-1}$ generates the affine space $\\K^{n-1}$ (remember that $\\# \\K>2$). Hence, $L(\\calV) \\subset L(U)$, leading to $\\dim L(\\calV) \\leq 1$. Then, by applying the same line of reasoning to $\\calS^T$, which satisfies the same assumptions, we would obtain $\\dim C(\\calV) \\leq 1$, contradicting $C(\\calV)=\\K^{n-1}$ (remember that $n-1 \\geq 2$).\n\n-   **Case 2: $\\K$ is finite.**\\\n    Then, we use a different strategy. Since $\\dim L(U)=1$ and ${\\operatorname{codim}}\\calS \\leq n-2$, we find a matrix $M_1 \\in \\calS$ such that $d(M_1) \\neq 0$. Since $C(\\calV)=\\K^{n-1}$, we also have $C(V)=\\K^{n-1}$. Hence, we can choose $M'_1 \\in V$ such that $C(M'_1)=-C(M_1)$. Hence, $M_2:=M_1+M'_1$ belongs to $\\calS$ and satisfies $d(M_2) \\neq 0$ and $C(M_2)=0$. As $n-1 \\geq 2$ and $\\K$ is a finite field, there exists a matrix $P \\in {\\operatorname{M}}_{n-1}(\\K)$ with no eigenvalue: it suffices to take $P$ as the companion matrix of an irreducible polynomial over $\\K$ with degree $n-1$. Since $A(T)={\\operatorname{M}}_{n-1}(\\K)$, we can add a well-chosen matrix of $T$ to $M_3$ so as to find a matrix $M_3 \\in \\calS$ such that $d(M_3) \\neq 0$, $C(M_3)=0$ and $A(M_3)=P$. Then, $\\det(M_3+t N)=d(M_3) \\det(P+t I_{n-1}) \\neq 0$ for all $t \\in \\K$, which contradicts our assumptions.\n\nIn any case, we have found a contradiction, which yields $A(T) \\subsetneq {\\operatorname{M}}_{n-1}(\\K)$.\n\nCombining the previous claim with identity and $\\dim \\calV>n(n-1)$ yields $$\\dim C(\\calV)+\\dim L(U) > n.$$ In particular, $$\\dim L(U)\\geq 2.$$\n\n\\[claimCStotal\\] One has $C(\\calV)=\\K^{n-1}$.\n\nAssume on the contrary that $C(\\calV)\\subsetneq \\K^{n-1}$. Then, $\\dim C(\\calV)=n-2$ by inequality . We deduce from inequality that, for all $X \\in C(\\calV)$, the space $A(T)_X$ has dimension $n-1$, and hence it contains every matrix of ${\\operatorname{M}}_{n-1}(\\K)$ with column space $\\K X$. As $A(T)\\subsetneq {\\operatorname{M}}_{n-1}(\\K)$, we deduce that ${\\operatorname{span}}(C(\\calV)) \\subsetneq \\K^{n-1}$, whence $C(\\calV)$ is a linear hyperplane of $\\K^{n-1}$.\n\nNext, let $Y_0 \\in C(\\calV)^\\bot$. We claim that $Y_0\\, A(T) \\subset \\K Y_0$, that is $Y_0\\, A(T) \\bot C(\\calV)$. Let $X \\in C(\\calV) {\\smallsetminus}L(U)^\\bot$. Let us prove that $Y_0 A(T) \\bot X$. No generality is lost in assuming that $$X=\\begin{bmatrix}\n1 \\\\\n[0]_{1 \\times (n-2)}\n\\end{bmatrix} \\quad \\text{and} \\quad\nY_0=\\begin{bmatrix}\n[0]_{1 \\times (n-2)} & 1\n\\end{bmatrix},$$ so that $C(\\calV)=\\K^{n-2} \\times \\{0\\}$. As $\\dim C(\\calV)=n-2$ and ${\\operatorname{codim}}A(T)>0$, inequality yields $\\dim L(U) \\geq 3$. Then, we can find $M \\in \\calV$ such that $C(M)=X$, $L(M)X=0$ and $L(M) \\notin \\K Y_0$: indeed, we know that we can find $M_1 \\in \\calV$ such that $C(M_1)=X$ and $L(M_1)X=0$ (see Claim \\[claim1\\]). Then, $L(U) \\cap \\{X\\}^\\bot$ has dimension at least $2$; we can choose $Z$ in $(L(U) \\cap \\{X\\}^\\bot) {\\smallsetminus}\\K Y_0$; then, we can choose $M_2 \\in U$ such that $L(M_2)=Z$, and we check that one of the matrices $M_1$ or $M_1+M_2$ must fulfill our needs.\n\nWithout further loss of generality, we can assume that $L(M)=\\begin{bmatrix}\n0 & 1 & [0]_{1 \\times (n-3)}\n\\end{bmatrix}$. Assume that there exists a matrix $J$ of $A(T)$ such that $Y_0 J$ is not orthogonal to $X$. Then, for some $a \\in \\K {\\smallsetminus}\\{0\\}$, we have $$J=\\begin{bmatrix}\n[?]_{(n-2) \\times 1} & [?]_{(n-2) \\times (n-2)} \\\\\na & [?]_{1 \\times (n-2)}\n\\end{bmatrix}.$$ Since $A(T)$ contains every matrix with column space $\\K X'$, for all $X' \\in \\K^{n-2} \\times \\{0\\}$, we deduce that there is a matrix $M'$ of $\\calV$ such that $C(M')=X$, $L(M')=L(M)$ and $$A(M')=\\begin{bmatrix}\n0 & 0 & [0]_{1 \\times (n-3)} \\\\\n[0]_{(n-3) \\times 1} & [0]_{(n-3) \\times 1} & I_{n-3} \\\\\na & ? & [?]_{1 \\times (n-3)}\n\\end{bmatrix}$$ Then, one checks that $\\det (M'+t N)=(-1)^{n-1} a$, which contradicts our assumptions.\n\nHence, $Y_0\\, A(T) \\bot X$ for all $X \\in C(\\calV) {\\smallsetminus}L(U)^\\bot$. Since $\\dim L(U) \\geq 2$ and $\\dim C(\\calV)=n-2$, we find that $L(U)^\\bot \\cap C(\\calV)$ is a proper linear subspace of $C(\\calV)$, and we conclude that $Y_0\\, A(T) \\bot C(\\calV)$, as claimed.\n\nHence, $Y_0\\, A(T) \\subset \\K Y_0$. In turn, this shows that ${\\operatorname{codim}}A(T) \\geq n-2$, and as ${\\operatorname{codim}}C(\\calV)=1$ we deduce that ${\\operatorname{codim}}\\calV \\geq n$, contradicting our assumptions.\n\n\\[claimcodimAT\\] One has ${\\operatorname{codim}}A(T)=1$.\n\nAssume that such is not the case. Let us consider the orthogonal $W$ of $A(T)$ for the non-degenerate symmetric bilinear form $(Z_1,Z_2) \\mapsto {\\operatorname{tr}}(Z_1Z_2)$ on ${\\operatorname{M}}_{n-1}(\\K)$. Then, $\\dim W \\geq 2$.\n\nThe set $\\widehat{W}:=\\{Z \\in W \\mapsto ZX \\mid X \\in \\K^{n-1}\\}$ is a linear subspace of $\\calL(W,\\K^{n-1})$, and we claim that every operator in it has rank at most $1$. Assume that such is not the case. Then, we can find respective bases of $W$ and $\\K^{n-1}$ in which one of the operators of $\\widehat{W}$ is represented by $\\begin{bmatrix}\nI_s & [0] \\\\\n[0] & [0]\n\\end{bmatrix}$ for some integer $s \\geq 2$. By assigning to every $X \\in \\K^{n-1}$ the determinant of the upper-left $2$ by $2$ submatrix of the matrix representing $Z \\mapsto ZX$ in the said bases, we define a non-zero quadratic form $q$ on $\\K^{n-1}$ that vanishes at every vector $X \\in \\K^{n-1}$ such that $Z \\in W \\mapsto ZX$ has rank $1$. For all $X \\in \\K^{n-1} {\\smallsetminus}L(U)^\\bot$, we know that $\\dim A(T)_X \\geq n-2$ (see Claim \\[claim2\\]) and hence ${\\operatorname{rk}}(Z \\in W \\mapsto ZX) \\leq 1$. Therefore, $q$ vanishes at every vector of $\\K^{n-1} {\\smallsetminus}L(U)^\\bot$. Yet, $L(U)^\\bot$ has codimension at least $2$ in $\\K^{n-1}$. Then, we deduce that $q=0$: if $\\# \\K>2$, this is easily obtained by choosing a non-zero linear form $\\varphi$ on $\\K^{n-1}$ that vanishes everywhere on $L(U)^\\bot$, and by noting that the homogenous polynomial $x \\mapsto q(x)\\varphi(x)$ with degree $3$ vanishes everywhere on $\\K^{n-1}$; if $\\# \\K=2$ the statement follows directly from Lemma 5.2 of [@dSPRC1]. This contradicts our assumptions.\n\nThus, $\\widehat{W}$ is a linear subspace of $\\calL(W,\\K^{n-1})$ in which every operator has rank at most $1$. As $\\dim W>1$ and no vector of $W {\\smallsetminus}\\{0\\}$ is annihilated by all the operators in $\\widehat{W}$, the classification of vector spaces of rank $1$ operators shows that there exists a $1$-dimensional linear subspace $D$ of $\\K^{n-1}$ that includes the range of every operator in $\\widehat{W}$, which shows that ${\\operatorname{Im}}Z \\subset D$ for all $Z \\in W$.\n\nFinally, as neither our assumptions nor our conclusion are modified in transposing both $N$ and $\\calS$, we obtain that the above property holds for $W^T$ as well, yielding a linear hyperplane $H$ of $\\K^{n-1}$ such that $H \\subset {\\operatorname{Ker}}Z$ for all $Z \\in W$. However, the space of all matrices $M \\in {\\operatorname{M}}_{n-1}(\\K)$ such that ${\\operatorname{Im}}M \\subset D$ and $H \\subset {\\operatorname{Ker}}M$ has dimension $1$, contradicting the assumption that $\\dim W \\geq 2$.\n\nNow, we are about to conclude. We know that $C(\\calV)=\\K^{n-1}$ and that $L(U)^\\bot$ is a proper linear subspace of $\\K^{n-1}$ (since $\\dim L(U)>0$). If, for all $X \\in C(\\calV) {\\smallsetminus}L(U)^\\bot$, we had $\\dim A(T)_X=n-1$, it would follow that $A(T)={\\operatorname{M}}_{n-1}(\\K)$, contradicting Claim \\[claimcodimAT\\]. Thus, we can find $X \\in C(\\calV) {\\smallsetminus}L(U)^\\bot$ such that $\\dim A(T)_X<n-1$. As in the proof of Claim \\[claimCStotal\\] (see its second paragraph), since $\\dim L(U) \\geq 2$ we can find a matrix $M_1 \\in \\calV$ such that $C(M_1)=X$, $L(M_1)C(M_1)=0$ and $L(M_1) \\neq 0$. Without loss of generality we can assume that $X=\\begin{bmatrix}\n1 \\\\\n[0]_{(n-2) \\times 1}\n\\end{bmatrix}$ and $L(M_1)=\\begin{bmatrix}\n[0]_{1 \\times (n-2)} & 1\n\\end{bmatrix}$. Now, as ${\\operatorname{codim}}A(T)=1$ and $\\dim A(T)_X<n-1$, the rank theorem yields that for every $H \\in {\\operatorname{M}}_{n-2,n-1}(\\K)$, there exists a matrix of $A(T)$ of the form $\\begin{bmatrix}\n[?]_{1 \\times (n-1)} \\\\\nH\n\\end{bmatrix}$. Thus, by adding a well-chosen matrix of $T$ to $M_1$, we reduce the situation to the one where $$M_1=\\begin{bmatrix}\n[?]_{1 \\times (n-2)} & ? & 1 \\\\\nI_{n-2} & [0]_{(n-2) \\times 1} & [0]_{(n-2) \\times 1} \\\\\n[0]_{1 \\times (n-2)} & 1 & 0\n\\end{bmatrix}.$$ Then, one checks that $\\det(M_1+t N)=(-1)^{n+1}$, which contradicts our initial assumptions.\n\nThis final contradiction shows that $\\calS$ contains a matrix $M$ such that $\\forall t \\in \\K, \\; \\det(M+tN) \\neq 0$. This completes the inductive proof.\n\nProof of Theorem \\[squaretheorem\\]\n==================================\n\nWe shall prove Theorem \\[squaretheorem\\] by induction on $n$ and $r$. Without loss of generality, we can assume that $N=\\begin{bmatrix}\nI_r & [0]_{r \\times (n-r)} \\\\\n[0]_{(n-r) \\times r} & [0]_{(n-r) \\times (n-r)}\n\\end{bmatrix}$ where $r:={\\operatorname{rk}}N$. If $\\calS={\\operatorname{M}}_n(\\K)$ the result is known from Lemma \\[fullspacelemma\\]. In the rest of the proof, we assume that $\\calS$ is a proper subspace of ${\\operatorname{M}}_n(\\K)$, and we denote by $S$ its translation vector space.\n\nIn particular, the case $n\\leq 2$ is settled, and we assume that $n \\geq 3$. We perform a *reductio ad absurdum*, by assuming that $\\calS$ does not contain a matrix $A$ of the required form. Theorem \\[penciltheorem\\] gives the case when $r=n-1$. In the rest of the proof, we assume that $r<n-1$. We write every matrix $M$ of ${\\operatorname{M}}_n(\\K)$ as $$M=\\begin{bmatrix}\nA(M) & C(M) \\\\\nB(M) & D(M)\n\\end{bmatrix}$$ with $A(M) \\in {\\operatorname{M}}_r(\\K)$, $B(M) \\in {\\operatorname{M}}_{n-r,r}(\\K)$, $C(M) \\in {\\operatorname{M}}_{r,n-r}(\\K)$ and $D(M) \\in {\\operatorname{M}}_{n-r}(\\K)$.\n\nThe assumptions tell us that there exists $M_1 \\in \\calS$ such that $D(M_1)$ has rank less than $n-r$. We distinguish between two cases.\n\n**Case 1: There exists a matrix $M_1 \\in \\calS$ such that $0<{\\operatorname{rk}}D(M_1)<n-r$.**\\\nSet $s:={\\operatorname{rk}}D(M_1)$. By conjugating $\\calS$ with a matrix of the form $I_r \\oplus P$ for some well-chosen $P \\in {\\operatorname{GL}}_{n-r}(\\K)$, we see that no generality is lost in assuming that $D(M_1)=\\begin{bmatrix}\n[0] & [0] \\\\\n[0] & I_s\n\\end{bmatrix}$. Then, by applying row operations of the form $L_i \\leftarrow L_i+\\lambda L_n$ with $i \\in \\lcro 1,r\\rcro$ and $\\lambda \\in \\K$ and column operations of the form $C_j \\leftarrow C_j+\\mu C_n$ with $j \\in \\lcro 1,r\\rcro$ and $\\mu \\in \\K$, no further generality is lost in assuming that the last row of $B(M_1)$ is zero and the last column of $C(M_1)$ is zero.\n\nDenote by $\\calS'$ the affine subspace of $\\calS$ consisting of the matrices with the same last row as $M_1$. Let us then write every matrix $M$ of $\\calS'$ as $$M=\\begin{bmatrix}\nK(M) & [?]_{(n-1) \\times 1} \\\\\n[0]_{1 \\times (n-1)} & 1\n\\end{bmatrix} \\quad \\text{with $K(M) \\in {\\operatorname{M}}_{n-1}(\\K)$.}$$ Then, with $N':=\\begin{bmatrix}\nI_r & [0]_{r \\times (n-r-1)} \\\\\n[0]_{(n-1-r) \\times r} & [0]_{(n-1-r) \\times (n-1-r)}\n\\end{bmatrix} \\in {\\operatorname{M}}_{n-1}(\\K)$, we see that $K(M_1)$ is a matrix of $K(\\calS')$ such that $X \\in {\\operatorname{Ker}}N' \\mapsto \\overline{K(M_1) X} \\in \\K^{n-1}/{\\operatorname{Im}}N'$ has rank at most $n-2-r$ (as the first column of $D(M_1)$ is zero). If ${\\operatorname{codim}}K(\\calS')\\leq n-3$, then by induction we find that $K(\\calS')$ contains a matrix $A'$ such that every matrix of $A'+\\K N'$ is invertible: writing $A'=K(A)$ for some $A \\in \\calS'$, we readily obtain that $\\det(A+t N)=\\det(A'+t N')$ for all $t$ in $\\K$, which yields that $A+tN$ is invertible for all $t \\in \\K$. Hence, ${\\operatorname{codim}}K(\\calS')\\geq n-2$, and as ${\\operatorname{codim}}\\calS \\leq n-2$ we deduce from the rank theorem that $S$ contains $E_{1,n},E_{2,n},\\dots,E_{n-1,n}$.\n\nSimilarly, by considering the subspace of all matrices of $\\calS$ with the same last column as $M_1$, we find that $S$ contains $E_{n,1},\\dots,E_{n,n-1}$.\n\nNow, let $i \\in \\lcro 1,n-1\\rcro$. Denote by $\\calS_1$ the affine space deduced from $\\calS$ by the row operation $L_i \\leftarrow L_i-L_n$ (which leaves $N$ invariant). As $\\calS$ contains $M_1+E_{i,n}$, we see that $\\calS_1$ also contains $M_1$. Now, obviously $\\calS_1$ satisfies all our assumptions with respect to $N$, and it follows from our first step that the translation vector space of $\\calS_1$ contains $E_{n,1},\\dots,E_{n,n-1}$. Hence, $S$ contains $E_{n,1}+E_{i,1},\\dots,E_{n,n-1}+E_{i,n-1}$. As $S$ also contains $E_{n,1},\\dots,E_{n,n-1}$, we deduce that it contains $E_{i,1},\\dots,E_{i,n-1}$. Similarly, we obtain that, for all $j \\in \\lcro 1,n\\rcro$, the space $S$ contains $E_{1,j},\\dots,E_{n-1,j}$. Hence, $S$ contains $E_{i,j}$ for all $(i,j)\\in  \\lcro 1,n\\rcro^2 {\\smallsetminus}\\{(n,n)\\}$. Then, the matrix $A:=E_{n,n}+E_{1,n-1}+\\underset{i=1}{\\overset{n-2}{\\sum}} E_{i+1,i}$ belongs to $\\calS$, and one checks that the polynomial $\\det(A+tN)$ is constant and non-zero, whence every matrix of $A+\\K N$ is invertible. This contradicts our assumptions.\n\n**Case 2: For every matrix $R$ of $D(\\calS)$, either $R=0$ or $R$ is invertible.**\\\nOur assumptions then show that $D(\\calS)$ contains $0$, and hence it is a linear subspace of ${\\operatorname{M}}_{n-r}(\\K)$. Every matrix of $D(\\calS)$ with first row zero equals zero, and hence $\\dim D(\\calS) \\leq n-r$.\n\nNow, denote by $\\calT$ the affine subspace of $\\calS$ consisting of its matrices $M$ such that $D(M)=0$. For $M \\in \\calT$, let us write $$C(M)=\\begin{bmatrix}\nC_1(M) & \\cdots & C_{n-r}(M)\n\\end{bmatrix}.$$ If $C_1(\\calT)=\\{0\\}$ then the rank theorem would yield ${\\operatorname{codim}}\\calS \\geq r+(n-r)=n$, contradicting our assumptions. Thus, there exists $M_1 \\in \\calT$ such that $C_1(M_1) \\neq 0$. Without loss of generality, we can assume that $C_1(M_1)=\\begin{bmatrix}\n1 \\\\\n[0]_{(r-1) \\times 1}\n\\end{bmatrix}$. Denote by $\\calT'$ the space of all matrices of $\\calT$ with the same $(r+1)$-th column as $M_1$. For all $M \\in {\\operatorname{M}}_n(\\K)$, we denote by $K(M)$ the submatrix of $M$ obtained by deleting the first row and the $(r+1)$-th column. Assume that ${\\operatorname{codim}}K(\\calT') \\leq n-3$. Then, the induction hypothesis applies to $K(\\calT')$ and to $K(N')$: indeed, every matrix of $K(\\calT')$ maps ${\\operatorname{Ker}}K(N)$ into ${\\operatorname{Im}}K(N)$, and hence no such matrix induces an isomorphism from ${\\operatorname{Ker}}K(N)$ to $\\K^{n-1}/{\\operatorname{Im}}K(N)$ (because $n-1>r$). Thus, we recover a matrix $M \\in \\calT'$ such that $K(M)+t K(N)$ is invertible for all $t$ in $\\K$, and as $\\det(M+t N)=(-1)^r \\det(K(M)+t K(N))$ for all $t \\in \\K$, we see that $M+t N$ in invertible for all $t \\in \\K$.\n\nHence, ${\\operatorname{codim}}K(\\calT) \\geq n-2$. Yet, ${\\operatorname{codim}}\\calS \\leq n-2$. By the rank theorem, it follows that $C_1(\\calT)=\\K^r$ and that $S$ contains $E_{1,1},\\dots,E_{1,r},E_{1,r+2},\\dots,E_{1,n}$.\n\nAs $C_1(\\calT)=\\K^r$, we can apply the previous step to every non-zero vector of $\\K^r$ rather than only to the first one of the standard basis. It follows that $S$ contains $E_{i,j}$ for all $j \\in \\lcro 1,n\\rcro {\\smallsetminus}\\{r+1\\}$ and all $i \\in \\lcro 1,r\\rcro$. With the same method applied to $C_k$, for all $k \\in \\lcro r+1,n\\rcro$, we obtain that $S$ contains $E_{i,j}$ for all $(i,j)\\in \\lcro 1,r\\rcro \\times \\lcro 1,n-1\\rcro$.\n\nNow, by applying the previous step to $\\calS^T$ we obtain that $S$ contains $E_{i,j}$ for all $(i,j)\\in \\lcro 1,n\\rcro \\times \\lcro 1,r\\rcro$. Therefore, $\\calT$ is the set of all $M \\in {\\operatorname{M}}_n(\\K)$ such that $D(M)=0$.\n\nWe are about to conclude. As $\\dim D(\\calS) \\leq n-r$ and ${\\operatorname{codim}}\\calS \\leq n-2$, we see that $(n-r)(n-r-1) \\leq n-2$. Setting $s:=n-r$, we deduce that if $s >\\frac{n}{2}$ then $\\frac{n+1}{2}\\,\\frac{n-1}{2} \\leq n-2$ (since $n>1$) which would lead to $n^2-4n+7 \\leq 0$, that is $(n-2)^2+3 \\leq 0$. Therefore $s \\leq \\frac{n}{2}$, that is $r \\geq n-r$. It follows that the matrix $A:=\\underset{i=1}{\\overset{r}{\\sum}} E_{i,n-r+i}+\\underset{j=1}{\\overset{n-r}{\\sum}} E_{r+j,j}$ belongs to $\\calT$, and one checks that the polynomial $\\det(A+t N)$ is constant and non-zero, whence every matrix of $A+\\K N$ is invertible.\n\nThis completes our inductive proof of Theorem \\[squaretheorem\\].\n\nProof of Theorem \\[rectangulartheorem\\] {#conclusionsection}\n=======================================\n\nWe actually prove the \u201coperator space\" version of Theorem \\[rectangulartheorem\\], that is Theorem \\[operatortheorem\\]. Once more, we use an induction over $\\dim V$, with $U$ fixed. Set $n:=\\dim V$ and $p:=\\dim U$. The case $\\dim U=\\dim V$ is known by the operator space reformulation of Theorem \\[squaretheorem\\]: in that case indeed the zero operator belongs to $S$ and does not induce an injective operator from ${\\operatorname{Ker}}t$ to $V/{\\operatorname{Im}}t$. In the remainder of the proof, we assume that $\\dim V>\\dim U$.\n\nGiven a non-zero vector $y \\in V$, we denote by $\\pi_y : V \\rightarrow V/\\K y$ the canonical projection and we set $$S {\\operatorname{mod}}y:=\\{\\pi_y \\circ s \\mid s \\in S\\},$$ which is a linear subspace of $\\calL(U,V/\\K y)$.\n\nWe perform a *reductio ad absurdum*, by assuming that there is no operator $a \\in S$ such that every operator of $a+\\K t$ is injective.\n\nLet $y \\in V {\\smallsetminus}\\{0\\}$. Note that $\\pi_y \\circ t$ is non-injective. We claim that $S {\\operatorname{mod}}y$ contains no operator $a$ such that every operator in $a+\\K(\\pi_y \\circ t)$ is injective: indeed, if such an operator $a$ existed, then $a=\\pi_y \\circ a'$ for some $a' \\in S$, and hence, for all $\\lambda \\in \\K$, the operator $\\pi_y \\circ (a'+\\lambda t)$ would be injective, which would show that $a'+\\lambda t$ is injective. By induction, we deduce that ${\\operatorname{codim}}(S {\\operatorname{mod}}y) > (\\dim V-1)-2$ and hence ${\\operatorname{codim}}(S {\\operatorname{mod}}y)\\geq {\\operatorname{codim}}S$. It follows from the rank theorem that $S$ contains every operator of $\\calL(U,V)$ with range $\\K y$.\\\nVarying $y$ shows that $S=\\calL(U,V)$, and then Lemma \\[fullspacelemma\\] yields a contradiction.\n\nThis completes the proof of Theorem \\[rectangulartheorem\\].\n\n[1]{} J. Dieudonn\u00e9, [Sur une g\u00e9n\u00e9ralisation du groupe orthogonal \u00e0 quatre variables,]{} Arch. Math. [**1**]{} (1948) 282\u2013287.\n\nH. Flanders, [On spaces of linear transformations with bounded rank,]{} J. Lond. Math. Soc. [**37**]{} (1962) 10\u201316.\n\nR. Meshulam, [On the maximal rank in a subspace of matrices,]{} Quart. J. Math. Oxford (2) [**36**]{} (1985) 225\u2013229.\n\nC. de Seguins Pazzis, [Range-compatible homomorphisms on matrix spaces,]{} Linear Algebra Appl. [**484**]{} (2015) 237-289\n\nC. de Seguins Pazzis, [The affine preservers of non-singular matrices,]{} Arch. Math. [**95**]{} (2010) 333\u2013342.\n\nC. de Seguins Pazzis, [The Flanders theorem over division rings,]{} Preprint, arXiv: http://arxiv.org/abs/1504.01986\n\n[^1]: Universit\u00e9 de Versailles Saint-Quentin-en-Yvelines, Laboratoire de Math\u00e9matiques de Versailles, 45 avenue des Etats-Unis, 78035 Versailles cedex, France\n\n[^2]: e-mail address: dsp.prof@gmail.com\n"
}