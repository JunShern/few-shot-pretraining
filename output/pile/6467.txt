{
    "criteria": [
        {
            "criterion": "AllDocuments",
            "passed": true,
            "reason": "All documents pass."
        },
        {
            "criterion": "Domain",
            "passed": false,
            "reason": "Document source unavailable."
        },
        {
            "criterion": "QuestionAnswerStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "QuestionAnswerStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "FullyStructured",
            "passed": true,
            "reason": "Text contains Markdown."
        },
        {
            "criterion": "ExamStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ListPrefix",
            "passed": false,
            "reason": "Found 0 list prefixes. (Min: 5)"
        },
        {
            "criterion": "ListPrefixV2",
            "passed": true,
            "reason": "Text contains ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']."
        }
    ],
    "doc_id": "6467",
    "text": "\nDocker: Not Even a Linker - nkurz\nhttp://adamierymenko.com/docker-not-even-a-linker\n======\nbtrask\nFantastic article. We need more deconstruction of \"fads\" (which I don't mean\nin a pejorative sense) so that we can quickly understand them without\nsacrificing tens of thousands of man-hours slowly coming to terms with each\none. It would be much better if we could reason about the exact differences\nand benefits instead of getting bogged down in new terminology, etc.\n\nMore examples I've been thinking about:\n\n\\- Goroutines (fibers are equivalent to threads, but coroutines are different)\n\n\\- Safety and the unsafe keyword in Rust (not sure but the effective\ndifference seems to be default-allow versus default-deny)\n\n~~~\npjmlp\nRegarding those two examples, more than having explanations about them, it\nwould help if people cared about IT history and it was more accessible.\n\nCoroutines are easily explained in Modula-2 literature.\n\nSafe keyword in Rust goes back at very least to Ada and Modula-2. Also in\nOberon and its derivatives, Modula-3 (which inspired C#). The literature for\nthose systems also has lots of examples.\n\nBeing an old IT dog, that started when those technologies were new it is\nsometimes hard to me to see how new generations fail to find such information,\neven though it is available on the web. I guess the main cause is thatbone\nneeds to know what to search for.\n\n~~~\npjc50\nTech is strangely ahistorical. Not just practitioners not reading the\nliterature, but it seemingly being forgotten entirely. Possibly this is a side\neffect of so many of us being self-taught.\n\nIn another thread I've just been arguing with someone who thought that the\nDOOM code should have been thread-safe.\n\n~~~\nwslh\nI would say cyclical. Every day we read about a similar framework working in a\npopular language when that solution already existed for long time.\n\nBut this happens in other areas outside computer science. For example, modern\nmedicine rediscovering old medicine \"recipes\".\n\nThe problem in our field is when people talk all day about Docker while\nsurpressing LXC from the discussion.\n\n~~~\ndigi_owl\nI think it happens for different reasons though.\n\nWith medicine it boils down to a dismissal of folk remedies as placebo.\n\nBut with computing its because the old ways were developed on mainframes and\nminicomputers in an environment that current generation may only have heard\nstories about.\n\nThis because the micro-computer era was pretty much a mental reboot for\ncomputing, as little if any software crossed over (until fairly recently).\n\n------\nvezzy-fnord\nIt's been said several times before that a large incentive for Docker's\nadoption was to get around the dynamic linking hell that is present in most\nmodern Unix-likes.\n\nIt's funny the author mentions a \"world without linkers\" with my posting of an\narticle about the TAOS operating system today. Go look there if you want some\nprimers on achieving that.\n\nThat said, the author greatly oversells Docker's novelty.\n\n~~~\nGalanwe\n> \"the dynamic linking hell that is present in most modern Unix-likes\"\n\nWTF are you talking about...\n\nThere has never been a \"hell\" of dynamic linking problems on Unixes, this used\nto be a Windows problem. Even the \"most modern unix-likes\" doesn't make sense,\nsince \"most modern unix-likes\" do not even use similar linking models.\n\n~~~\nfapjacks\nWe have dependency management built into the package managers which hides that\nfrom us these days. Unix and Linux before package managers was kind of a pain.\nNow, I will totally give you that it was nothing like the \"DLL hell\" of\nWindows.\n\n~~~\nreidrac\nThen how can be that an incentive for Docker's adoption? Honest question; if,\nas you say, this is a solved problem thanks to package managers.\n\nI can't even remember the last time I had a real dependency problem deploying\nan application (using Debian; and CentOS before that), other than myself not\ndoing things right (read: installing RPMs I found online and I shouldn't\ninstall).\n\n~~~\nfapjacks\nWell I wasn't originally speaking wrt Docker, but Docker doesn't magically\nlose all the hard work done by package managers. You have total access to them\nin your containers.\n\n------\namirouche\n> Had their developers known what they were actually writing, perhaps we'd\n> have a lean and mean solution that did the right thing.\n\nI am surprised nobody mentionned nix, nixos and guix.\n\n~~~\npron\nCan you explain what those are and what they do?\n\n~~~\ndavexunit\nNix and Guix are purely functional package managers, meaning that software\nbuilds are treated like a mathematical function: Input the same source code +\ndependencies and receive the same build as output. They have features such as\nreproducibile (often bit identical) builds, transactional package upgrades and\nrollbacks, and unprivileged package management. They solve the dynamic linking\nproblem by allowing each package to refer _precisely_ to the dependencies that\nit was built with. With this mechanism in place, it becomes very easy to use\napplications that require different versions of some C library, or a different\nRuby/Python interpreter, or whatever else. Furthermore, it can do this without\nrelying on a specific type of file system, and without requiring that\napplications be run inside containers or virtual machines. This makes it very\ncomposable and general-purpose.\n\n[https://nixos.org/](https://nixos.org/)\n\n[http://www.gnu.org/software/guix/](http://www.gnu.org/software/guix/)\n\n------\nriquito\n> Instead of building and filing away heaps of immutable (read: security\n> nightmare) containers [...]\n\nIs there a consensus on what is(are) the best method(s) to handle security\npatches automatically in Docker? For example, the official images at\n[https://registry.hub.docker.com/](https://registry.hub.docker.com/) are fixed\nin time and you should apply security patches before using them?\n\n~~~\namouat\nThe official images aren't fixed in time, assuming you're pulling using a tag\ne.g redis:3.0. That image may be updated at any point and should be updated\nwith minor patches and security updates. Rather than manually apply patches,\njust pull the image again to get the updates. If the image hasn't been\nupdated, complain loudly.\n\nIf you want your image to be \"fixed in time\", pull by digest instead.\n\n~~~\nriquito\nThank you very much\n\n------\ncraneca0\nVery interesting. I'm not convinced this captures the core value of containers\nthough. Or at least not the only core value. Calling containers an evolution\nof configuration management tools seems like an oversimplification just to\nmake a point. This may be one aspect of building a micro-service driven\narchitecture that containers make easier, but there are other very important\nones. Portability comes to mind. It's not just that you can build your stack\nonce and save it, but that you can then run that stack anywhere, and it\nbecomes much easier to share/borrow bits and pieces of other people's stacks.\n\n~~~\nfalcolas\n> you can then run that stack anywhere\n\nAnywhere that runs Linux, at least.\n\n> it becomes much easier to share/borrow bits and pieces of other people's\n> stacks.\n\nAt the cost of not knowing what's really in them.\n\n~~~\nandybak\nTo a certain degree I don't _want_ to know what's in them. If I want to add\nsearch to my stack - initially I'd rather not have to have an intimate\nknowledge of Elastic Search, a task queue and whatever other moving parts\nthere are. In many cases a black box that just works would be a fantastic\noption.\n\nThe reason hosted services are popular is for exactly this reason.\n\nA wide understanding of different technologies is a wonderful thing but\nsometimes you just need to ship.\n\n------\nbgilroy26\nFor any 'Early coders' like my self who want to learn more about linkers and\nloaders based on this write up, Programming from the Ground Up by Jonathan\nBartlett is a good book.\n\n~~~\nvezzy-fnord\nAs well as Ian Lance Taylor's 20-part blog series on linkers:\n[https://lwn.net/Articles/276782/](https://lwn.net/Articles/276782/)\n\n------\ntwblalock\nShared libraries were considered a bad idea in Plan 9, and I really wish that\npoint of view had made it into commercial Unix and Linux.\n\n~~~\ndavexunit\nShared libraries are a fantastic idea. Static linking wastes system resources\nand makes system-wide library updates problematic. Docker's approach to things\nis essentially a higher level form of static linking, which is to say that\nit's not a very good approach. It's papering over the package management\nproblem. We need general-purpose package management systems that allow for\ndifferent applications to use different versions of shared libraries without\ninterference. Luckily, the Nix and GNU Guix projects solve this problem very\nwell, if only they could get some more \"mindshare.\"\n\n~~~\ne40\nYeah, having to rebuild every app that uses OpenSSL when a new advisory is\nissued... wow, that would be expensive!\n\n~~~\nadricnet\nThousands of mobile app developers feel this pain now, from that particular\nlibrary.\n\nNot updating these applications is not acceptable to most organizations /\ndevice operators.\n\nJust in case anyone thought the parent was sarcasm or theory, some refs:\n\n[http://www.digitaltrends.com/mobile/heartbleed-bug-apps-\naffe...](http://www.digitaltrends.com/mobile/heartbleed-bug-apps-affected-\nlist/)\n\n[http://blog.trendmicro.com/trendlabs-security-\nintelligence/b...](http://blog.trendmicro.com/trendlabs-security-\nintelligence/bundled-openssl-library-also-makes-apps-and-\nandroid-411-vulnerable-to-heartbleed/)\n\n------\nberzemus\nWhat's with the light-grey-text-on-white-background styling ? It may look\ngood, but it's a pain to read.\n\n~~~\ncthor\nIt looking \"prettier\" is pretty arguable.\n\nThe body text is as close to black as it is white. #444 is borderline\nacceptable. #888 is absurd.\n\n------\nkstenerud\nSorry, no. I don't want a dynamic linker for my software stacks. I want a\ncomplete, ready-to-deploy chunk of code, FROZEN IN TIME, that has a known and\npredictable state that I can trust.\n\nIf I need to apply security fixes, I'll rebuild the chunk of code, also frozen\nin time, and deploy.\n\nIdeally, I want no dependencies between container and host, or container and\ncontainer. Or at least I want them kept to an absolute minimum.\n\nEven more ideally, I want isolation to be so complete that I'd be able to run\nmy built stack 100 years from now and have it operate exactly the same as it\ndoes today. That's a bit hyperbolic, of course.\n\nDocker is not a linker; it is a system from which you build deployable code.\nIn fact, there's no reason why in theory you couldn't add support to deploy\nWindows or BSD stacks (other than the fact that Windows and BSD kernels\nhaven't been added yet).\n\n------\nBurritoAlPastor\nThis is an interesting take, but it doesn't entirely make sense. Ierymenko's\n'save your work' metaphor is a little misleading, since (I certainly hope)\nnobody is creating docker images manually. But I like his idea that dockerfile\ncreation, by which you set up a stack in a way that's automatically\nreproducible, is equivalent to the role of a linker in a compiled program.\n\nWhere he loses me is when he suggests that Puppet et al are closer to a 'pure'\nlinker. Configuration management systems are doing the _same thing_ as a\nDockerfile: instead of setting up your XYZ stack by hand, you write a Puppet\nmanifest that calls the modules for XYZ and sets them up the way you need.\nYour final result isn't a server with the XYZ stack: it's an _abstracted\nprocess_ that will _reproduce_ your XYZ stack. The main difference is the\nimplementation; Docker reproduces your stack in an isolated environment, and\nconfiguration management tools reproduce your stack on an arbitrary platform.\n\nBut nobody thinks of Docker as a configuration management tool, and for the\nmost part I don't think people even think of Docker as a _competitor_ to\nconfiguration management. Hell, Docker is a core component of many Puppet CI\nworkflows.\n\nSo there's something else going on here. What's the secret sauce? Is Docker\njust two great things (config management + virtualization) glued together so\ncohesively that it becomes greater than the sum of its parts?\n\n------\nd2xdy2\nThat's a very clever metaphor for that aspect of Docker. I hadn't considered\nlooking at it that way before.\n\n------\nwilliamsharkey\nThe author writes:\n\n\"Sometimes (unless I am writing in Go) I don't want to bundle all my code\ntogether into one giant hulking binary.\"\n\nI am unfamiliar with Go - can someone please offer why this technique might\nespecially desirable/feasible with Go?\n\n~~~\nagrover\nGo only supports static linking. No dynamic linking means no linking issues\nwhen deploying the same binary across a billion machines in the Googleplex.\n\n------\nglifchits\nIs \"gerschnorvels\" really a word in any language?\n\n~~~\ndigi_owl\nMy first though was that it was some sort of compound word.\n\n------\nleephillips\nAccording to this article, Docker is a way to save your work after configuring\nyour server. Can't I do that with\n\n    \n    \n        rsync -a /etc /whatever backupserver:/backups/server1\n    \n    ?\n\n~~~\nfragmede\nFirst off,\n\n    \n    \n        rsync -a / backupserver:/backups/server1\n    \n\nwould be a better comparison; full server state never properly stays in /etc.\n\nDo you actually do that though? Multiple times a day? How easy is it to roll\nback to a previous state?\n\nGiven Dockerfiles, a better comparison would be rsnapshot, since intermediate\nsteps are important, and maybe that last \"yum upgrade/apt-get update/whatever\"\nbroke something (on dev, of course) and you want to roll back.\n\nHow do you compare two related file system images? Is there something more\nadvanced than \"diff -u\"? How does that handle binaries? Will that map\nbackwards and say what command resulted in changed binaries? Can I submit a\ncode review for the changes between the two states like I could for a\nDockerfile which is plain text?\n\nDocker isn't quite a configuration management system like Chef or Puppet, but\nthere's a lot of overlap.\n\n------\nForHackernews\n> perhaps some quantum superposition of those that has yielded a New Thing.\n\nUgh. That's not what quantum superposition means.\n\n"
}