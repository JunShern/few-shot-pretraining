{
    "criteria": [
        {
            "criterion": "AllDocuments",
            "passed": true,
            "reason": "All documents pass."
        },
        {
            "criterion": "Domain",
            "passed": false,
            "reason": "Document source unavailable."
        },
        {
            "criterion": "QuestionAnswerStrings",
            "passed": true,
            "reason": "Text contains Q:."
        },
        {
            "criterion": "QuestionAnswerStringsV2",
            "passed": true,
            "reason": "Text contains ['Q:', 'A:']."
        },
        {
            "criterion": "FullyStructured",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ListPrefix",
            "passed": false,
            "reason": "Found 0 list prefixes. (Min: 5)"
        },
        {
            "criterion": "ListPrefixV2",
            "passed": true,
            "reason": "Text contains ['1', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '1', '1', '1']."
        }
    ],
    "doc_id": "1097",
    "text": "Q:\n\nHow to count rows efficiently with one pass over the dataframe\n\nI have a dataframe made of strings like this:\nID_0 ID_1\n g    k\n a    h\n c    i\n j    e\n d    i\n i    h\n b    b\n d    d\n i    a\n d    h\n\nFor each pair of strings I can count how many rows have either string in them  as follows.\nimport pandas as pd\nimport itertools\n\ndf = pd.read_csv(\"test.csv\", header=None, prefix=\"ID_\", usecols = [0,1])\n\nalphabet_1 = set(df['ID_0'])\nalphabet_2 = set(df['ID_1'])\n# This just makes a set of all the strings in the dataframe.\nalphabet = alphabet_1 | alphabet_2\n#This iterates over all pairs and counts how many rows have either in either column\nfor (x,y) in itertools.combinations(alphabet, 2):\n    print x, y, len(df.loc[df['ID_0'].isin([x,y]) | df['ID_1'].isin([x,y])])\n\nThis  gives:\na c 3\na b 3\na e 3\na d 5\na g 3\na i 5\na h 4\na k 3\na j 3\nc b 2\nc e 2\nc d 4\n[...]\n\nThe problem is that my dataframe is very large and the alphabet is of size 200 and this method does an independent traversal over the whole dataframe for each pair of letters.  \nIs it possible to get the same output by doing a single pass over the dataframe somehow?\n\nTimings\nI created some data with:\nimport numpy as np\nimport pandas as pd\nfrom string import ascii_lowercase\nn = 10**4\ndata = np.random.choice(list(ascii_lowercase), size=(n,2))\ndf = pd.DataFrame(data, columns=['ID_0', 'ID_1'])\n\n#Testing Parfait's answer\ndef f(row):\n    ser = len(df[(df['ID_0'] == row['ID_0']) | (df['ID_1'] == row['ID_0'])|\n                 (df['ID_0'] == row['ID_1']) | (df['ID_1'] == row['ID_1'])])\n    return(ser)\n\n%timeit df.apply(f, axis=1)\n1 loops, best of 3: 37.8 s per loop\n\nI would like to be able to do this for n = 10**8.  Can this be sped up?\n\nA:\n\nYou can get past the row level subiteration by using some clever combinatorics/set theory to do the counting:\n# Count of individual characters and pairs.\nchar_count = df['ID_0'].append(df.loc[df['ID_0'] != df['ID_1'], 'ID_1']).value_counts().to_dict()\npair_count = df.groupby(['ID_0', 'ID_1']).size().to_dict()\n\n# Get the counts.\ndf['count'] = [char_count[x]  if x == y else char_count[x] + char_count[y] - (pair_count[x,y] + pair_count.get((y,x),0)) for x,y in df[['ID_0', 'ID_1']].values]\n\nThe resulting output:\n  ID_0 ID_1  count\n0    g    k      1\n1    a    h      4\n2    c    i      4\n3    j    e      1\n4    d    i      6\n5    i    h      6\n6    b    b      1\n7    d    d      3\n8    i    a      5\n9    d    h      5\n\nI've compared the output of my method to the row level iteration method on a dataset with 5000 rows and all of the counts match.\nWhy does this work?  It essentially just relies on the formula for counting the union of two sets: \nThe cardinality of a given element is just the char_count.  When the elements are distinct, the cardinality of the intersection is just the count of pairs of the elements in any order.  Note that when the two elements are identical, the formula reduces to just the char_count.\nTimings\nUsing the timing setup in the question, and the following function for my answer:\ndef root(df):\n    char_count = df['ID_0'].append(df.loc[df['ID_0'] != df['ID_1'], 'ID_1']).value_counts().to_dict()\n    pair_count = df.groupby(['ID_0', 'ID_1']).size().to_dict()\n    df['count'] = [char_count[x]  if x == y else char_count[x] + char_count[y] - (pair_count[x,y] + pair_count.get((y,x),0)) for x,y in df[['ID_0', 'ID_1']].values]\n    return df\n\nI get the following timings for n=10**4:\n%timeit root(df.copy())\n10 loops, best of 3: 25 ms per loop\n\n%timeit df.apply(f, axis=1)\n1 loop, best of 3: 49.4 s per loop\n\nI get the following timing for n=10**6:\n%timeit root(df.copy())\n10 loops best of 3: 2.22 s per loop\n\nIt appears that my solution scales approximately linearly.\n\n"
}