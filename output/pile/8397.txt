{
    "criteria": [
        {
            "criterion": "AllDocuments",
            "passed": true,
            "reason": "All documents pass."
        },
        {
            "criterion": "Domain",
            "passed": false,
            "reason": "Document source unavailable."
        },
        {
            "criterion": "QuestionAnswerStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "QuestionAnswerStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "FullyStructured",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamStringsV2",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ExamplesStrings",
            "passed": false,
            "reason": "Does not meet criterion."
        },
        {
            "criterion": "ListPrefix",
            "passed": false,
            "reason": "Found 0 list prefixes. (Min: 5)"
        },
        {
            "criterion": "ListPrefixV2",
            "passed": true,
            "reason": "Text contains ['-', '-', '-', '-', '-', '-', '-', '-', '-', '-']."
        }
    ],
    "doc_id": "8397",
    "text": "---\nabstract: 'Nowadays we are often faced with huge databases resulting from the rapid growth of data storage technologies. This is particularly true when dealing with music databases. In this context, it is essential to have techniques and tools able to discriminate properties from these massive sets. In this work, we report on a statistical analysis of more than ten thousand songs aiming to obtain a complexity hierarchy. Our approach is based on the estimation of the permutation entropy combined with an intensive complexity measure, building up the complexity-entropy causality plane. The results obtained indicate that this representation space is very promising to discriminate songs as well as to allow a relative quantitative comparison among songs. Additionally, we believe that the here-reported method may be applied in practical situations since it is simple, robust and has a fast numerical implementation.'\naddress:\n- 'Departamento de F\u00edsica and National Institute of Science and Technology for Complex Systems, Universidade Estadual de Maring\u00e1, Av. Colombo 5790, 87020-900, Maring\u00e1, PR, Brazil'\n- 'Department of Chemical and Biological Engineering, Northwestern University, Evanston, IL 60208, USA'\n- 'Centro de Investigaciones \u00d3pticas (CONICET La Plata - CIC), C.C. 3, 1897 Gonnet, Argentina'\n- 'Departamento de Ciencias B\u00e1sicas, Facultad de Ingenier\u00eda, Universidad Nacional de La Plata (UNLP), 1900 La Plata, Argentina'\nauthor:\n- 'Haroldo V. Ribeiro'\n- Luciano Zunino\n- 'Renio S. Mendes'\n- 'Ervin K. Lenzi'\ntitle: 'Complexity-entropy causality plane: a useful approach for distinguishing songs'\n---\n\npermutation entropy ,music ,complexity measure ,time series analysis\n\nIntroduction\n============\n\nNowadays we are experimenting a rapid development of technologies related to data storage. As an immediate consequence, we are often faced with huge databases hindering the access to information. Thus, it is necessary to have techniques and tools able to discriminate elements from these massive databases. Text categorization\u00a0[@Sebastiani], scene classification\u00a0[@Radke] and protein classification\u00a0[@Enright] are just a few examples where this problem emerges. In a parallel direction, statistical physicists are increasingly interested in studying the so-called complex systems\u00a0[@Auyang; @Jensen; @Barabasi; @Sornette; @Boccara]. These investigations employ established methods of statistical mechanics as well as recent developments of this field aiming to extract hidden patterns that are governing the system\u2019s dynamics. In a similar way, this framework may help to advance in distinguishing elements within these databases, with the benefit of the simplicity often attributed to statistical physics methods.\n\nA very interesting case corresponds to the music databases, not only because of the incredible amount of data (for instance, the iTunes Store has more than 14 million songs), but also due to the ubiquity of music in our society as well as its deeply connection with cognitive habits and historical developments\u00a0[@DeNora]. In this direction, there are investigations focused on collective listening habits\u00a0[@Lambiotte; @Lambiotte2; @Buldu], collaboration networks among artists\u00a0[@Teitelbaum], music sales\u00a0[@Lambiotte3], success of musicians\u00a0[@Davies; @Borges; @Hu], among others. On the other hand, the sounds that compose the songs present several complex structures and emergent features which, in some cases, resemble very closely the patterns of out-of-equilibrium physics, such as scale-free statistics and universality. For instance, the seminal work of Voss and Clarke\u00a0[@Voss] showed that the power spectrum associated to the loudness variations and pitch fluctuations of radio stations (including songs and human voice) is characterized by $1/f$ noise-like pattern in the low frequency domain ($f \\leq 10 Hz$). Klimontovich and Boon\u00a0[@Klimontovich] argue that this behavior for low-frequency follows from a natural flicker noise theory. However, this finding has been questioned by Nettheim\u00a0[@Nettheim] and according to him the power spectrum may be better described by $1/f^2$. Fractal structures were also reported by Hs\u00fc and Hs\u00fc\u00a0[@Hsu2; @Hsu] when studying classical pieces concerning frequency intervals. It was also found that the distribution of sound amplitudes may be adjusted by a one-parameter stretched Gaussian and that this non-Gaussian feature is related to correlation aspects present in the songs\u00a0[@Mendes].\n\nThese features and others have attracted the attention of statistical physicists, who have attempted to obtain some quantifiers able to distinguish songs and genres. One of these efforts was made by Jennings et al.\u00a0[@Jennings] who found that the Hurst exponent estimated from the volatility of the sound intensity depends on the music genre. Correa et al.\u00a0[@Correa] investigated four music genres employing a complex network representation for rhythmic features of the songs. There are still other investigations\u00a0[@Boon; @Bigerelle; @Diodati; @Gunduz; @Su2; @Scaringella; @Jafari; @Dagdug; @Su; @Rio; @Ro; @Serra; @Mostafa; @Boon2], most of which are based on fractal dimensions, entropies, power spectrum analysis or correlation analysis. It is worth noting that there are several methods of automatic genre classification emerging from engineering disciplines (see, for instance, Ref.\u00a0[@Tzanetakis]). [In particular, there exists a very active community working on music classification problems and several important results are published at the ISMIR\u00a0[@ISMIR] conferences (just to mention a few please see Refs.\u00a0[@ISMIR1; @ISMIR2; @ISMIR3; @ISMIR4; @ISMIR5; @ISMIR6; @ISMIR7; @ISMIR8; @ISMIR9; @ISMIR10; @ISMIR11; @ISMIR12; @ISMIR13].)]{}\n\nHowever, the music genre it not a well defined concept\u00a0[@Scaringella], and, specially, the boundaries between genres still remain fuzzy. Thus, any taxonomy may be controversial, representing a challenging and open problem of pattern recognition. In addition, some of the proposed quantifiers require specific algorithms or recipes for processing the sound of the songs, which may depend on tuning parameters.\n\nHere, we follow an Information Theory approach trying to quantify aspects of songs. More specifically, the Bandt and Pompe approach\u00a0[@Bandt] is applied in order to obtain a complexity hierarchy for songs. This method defines a \u201cnatural\u201d complexity measure for time series based on ordinal patterns. Although this concept has not been explored yet within the context of music, it has been successfully applied in other areas, such as medical\u00a0[@Li; @Nicolaou], financial\u00a0[@Zunino; @Zunino3] and climatological time series\u00a0[@Saco; @Barreiro]. In this direction, our main goal is to fill this hiatus employing the Bandt and Pompe approach together with a non-trivial entropic measure\u00a0[@LopezRuiz; @Martin; @Lamberti], constructing the so-called complexity-entropy causality plane\u00a0[@Zunino; @Zunino3; @Rosso; @Zunino2]. As it will be discussed in detail below, we have found that this representation space is very promising to distinguish songs from huge databases. Moreover, thanks to the simple and fast implementation it is possible to conjecture its use in practical situations. In the following, we review some aspects related to the Bandt and Pompe approach as well as the complexity-entropy causality plane (Section 2). Next, we describe our database and the results (Section 3). Finally, we end this work with some concluding comments (Section 4).\n\nMethods\n=======\n\nThe essence of the permutation entropy proposed by Bandt and Pompe\u00a0[@Bandt] is to associate a symbolic sequence to the time series under analysis. This is done by employing a suitable partition based on ordinal patterns obtained by comparing neighboring values of the original series. To be more specific, consider a given time series $\\{x_t\\}_{t=1,\\dots,N}$ and the following partitions represented by a $d$-dimensional vector ($d>1, D \\in \\mathbb{N}$) $$(s)\\mapsto (x_{s-(d-1)},x_{s-(d-2)},\\dots,x_{s-1},x_{s})\\;,$$ with $s=d,d+1,\\dots,N$. For each one of these $(N-d+1)$ vectors, we investigate the permutations of $(0,1,\\dots,d-1)$ defined by $x_{s-r_{d-1}}\\leq x_{s-r_{d-2}}\\leq \\dots \\leq x_{s-r_{1}} \\leq x_{s-r_{0}}$, and, for all $d\\, !$ possible permutations of $\\pi$, we evaluate the probability distribution $P=\\{p(\\pi)\\}$ given by $$p(\\pi) = \\frac{\\#\\{s|s\\leq N-d+1;~ (s) ~\\text{has type}~ \\pi \\}}{N-d+1}\\;,$$ where the symbol $\\#$ stands for the number (frequency) of occurrences of the permutation $\\pi$. Thus, we define the normalized permutation entropy of order by $$H_s[P]=\\frac{S[P]}{\\log d\\,!}\\;,$$ with $S[P]$ being the standard Shannon\u2019s entropy\u00a0[@Shannon]. Naturally, $0 \\leq H_s[P] \\leq 1$, where the upper bound occurs for a completely random system, i.e., a system for which all $d\\,!$ possible permutations are equiprobable. If the time series exhibits some kind of ordering dynamics $H_s[P]$ will be smaller than one. As pointed out by Bandt and Pompe\u00a0[@Bandt], the advantages in using this method lie on its simplicity, robustness and very fast computational evaluation. Clearly, the parameter $d$ (known as embedding dimension) plays an important role in the estimation of the permutation probability distribution $P$, since it determines the number of accessible states. In fact, the choice of $d$ depends on the length $N$ of the time series in such a way that the condition $d\\,!\\ll N$ must be satisfied in order to obtain a reliable statistics. For practical purposes, Bandt and Pompe recommend $d=3,\\dots,7$. Here, we have fixed $d=5$ because the time series under analysis are large enough (they have more than one million of data values). [We have verified that the results are robust concerning the choice of the embedding dimension $d$.]{}\n\nAdvancing with this brief revision, we now introduce another statistical complexity measure able to quantify the degree of physical structure present in a time series\u00a0[@LopezRuiz; @Martin; @Lamberti]. Given a probability distribution $P$, this quantifier is defined by the product of the normalized entropy $H_s$, and a suitable metric distance between $P$ and the uniform distribution $P_e=\\{1/d\\,!\\}$. Mathematically, we may write $$C_{js}[P]=Q_j[P,P_e]\\,H_s[P]\\,,$$ where $$Q_j[P,P_e] = \\frac{S[(P+P_e)/2] - S[P]/2 - S[P_e]/2}{Q_{\\text{max}}}\\,$$ and $Q_{\\text{max}}$ is the maximum possible value of $Q_j[P,P_e]$, obtained when one of the components of $P$ is equal to one and all the others vanish, i.e., $$Q_{\\text{max}}=-\\frac{1}{2}\\left[ \\frac{d\\,!+1}{d\\,!} \\log(d\\,!+1) - 2 \\log(2 d\\,!) + \\log(d\\,!) \\right]\\,.$$ The quantity $Q_j$, usually known as disequilibrium, will be different from zero if there are more likely states among the accessible ones. It is worth noting that the complexity measure $C_{js}$ is not a trivial function of the entropy\u00a0[@LopezRuiz] because it depends on two different probability distributions, the one associated to the system under analysis, $P$, and the uniform distribution, $P_e$. It quantifies the existence of correlational structures, providing important additional information that may not be carried only by the permutation entropy. Furthermore, it was shown that for a given $H_s$ value, there exists a range of possible $C_{js}$ values\u00a0[@Martin2]. Motivated by the previous discussion, Rosso et al.\u00a0[@Rosso] proposed to employ a diagram of $C_{js}$ versus $H_s$ for distinguishing between stochasticity and chaoticity. This representation space, called complexity-entropy causality plane\u00a0[@Rosso; @Zunino; @Zunino3], herein will be our approach for distinguishing songs.\n\n[The concept of ordinal patterns can be straightforward generalized for non-consecutive samples, introducing a lag of $\\tau$ (usually known as embedding delay) sampling times. With $\\tau=1$ the consecutive case is recovered, and the analysis focuses on the highest frequency contained within the time series. It is clear that different time scales are taken into account by changing the embedding delays of the symbolic reconstruction. The importance of selecting an appropriate embedding delay in the estimation of the permutation quantifiers has been recently confirmed for different purposes, like identifying intrinsic time scales of delayed systems\u00a0[@zunino2010; @soriano2011], quantifying the degree of unpredictability of the high-dimensional chaotic fluctuations of a semiconductor laser subject to optical feedback\u00a0[@zunino2011], and classifying cardiac biosignals\u00a0[@parlitz2011]. We have found that an embedding delay $\\tau=1$ is the optimal one for our music categorization goal since when this parameter is increased the permutation entropy increases and the permutation statistical complexity decreases. Thus, the range of variation of both quantifiers is smaller and, consequently, it is more difficult to distinguish songs and genres.]{}\n\nData Presentation and Results\n=============================\n\nIt is clear that a music piece can be naturally considered as the time evolution of an acoustic signal and time irreversibility is inherent to musical expression\u00a0[@Boon; @Boon2]. From the physical point of view, the songs may be considered as pressure fluctuations traveling through the air. These waves are perceived by the auditory system leading the sense of hearing. In the case of recordings, these fluctuations are converted into a voltage signal by a record system and then stored, for instance, in a compact disc (CD). The perception of sound is usually limited to a certain range of frequencies - for human beings the full audible range is approximately between 20 Hz and 20 kHz. Because of this limitation the record systems often employ a sampling rate of 44.1 kHz encompassing all the previous spectrum. All the songs analyzed here have this sampling rate.\n\nOur database consists of 10124 songs distributed into ten different music genres, they are: blues (1020), classical (997), flamenco (679), hiphop (1000), jazz (700), metal (1638), Brazilian popular music - mpb (580), pop (1000), tango (1016) and techno (1494). The songs were chosen aiming to cover a large number of composers and singers. To achieve this [and also to determine the music genre via an external judgment]{}, we tried to select CDs that are compilations of a given genre or from representative musical groups [of a given genre]{}.\n\n![A graphical representation of 4 songs from 4 different genres. In the left panel we show the amplitude series and in the right panel the intensity series. The music genres are blues, classic, metal and techno, respectively.[]{data-label=\"fig:sample\"}](fig1.pdf)\n\nBy using the previous database, we focus our analysis on two times series directly obtained from the digitized files that represent each song - the sound amplitude series and the sound intensity series, i.e., the square of the amplitude. Figure\u00a0\\[fig:sample\\] shows these two time series for several songs. We evaluate the normalized entropy $H_s$ and the statistical complexity measure $C_{js}$ for the amplitude and intensity series associated to each song as shown in Figs.\u00a0\\[fig:plane\\]a and \\[fig:plane\\]b. Notice that both series, amplitude and intensity, lead to similar behavior, contrarily to what happens with other quantifiers. For instance, when dealing with Hurst exponent is preferable to work with the intensities\u00a0[@Mendes] or volatilities\u00a0[@Jennings], since the amplitudes are intrinsically anti-correlated due the oscillatory nature of the sound. Moreover, we have found that there is a large range of $H_s$ and $C_{js}$ possible values. This wide variation allows a relative comparison among songs and someone may ask to listen songs that are limited within some interval of $H_s$ and/or $C_{js}$ values. We also evaluate the mean values of $C_{js}$ and $H_s$ over all songs grouped by genre as shown by Figs. \\[fig:plane\\]c and \\[fig:plane\\]d. These mean values enable us to quantify the complexity of each music genre. In particular, we can observe that high art music genres (e.g. classic, jazz and tango) are located in the central part of the complexity plane, being equally distant from the fully aleatory limit ($H_s\\to1$ and $C_{js}\\to0$) and also from the completely regular case ($H_s\\to0$ and $C_{js}\\to0$). On the other hand, light/dance music genres (e.g. pop and techno) are located closer to the fully aleatory limit (white noise). In this context, our approach agrees with other works\u00a0[@Mendes; @Jennings; @Diodati].\n\n![(color online) Complexity-entropy causality plane, i.e., $C_{js}$ versus $H_s$ for all the songs when considering the (a) amplitude series and (b) the intensity series. In (c) and (d), we show the mean value of $C_{js}$ and $H_s$ for each genre. The upper (bottom) dashed line represents the maximum (minimum) value of $C_{js}$ as a function of $H_s$ for $d=5$ and the different symbols refer to the 10 different genres. For a better visualization of the different genres see also Figs. \\[fig:ampgenre\\] and \\[fig:intgenre\\].[]{data-label=\"fig:plane\"}](fig2.pdf)\n\n![Complexity-entropy causality plane for the amplitude series by music genres when considering the original and shuffled series. The upper (bottom) dashed line represents the maximum (minimum) value of $C_{js}$ as a function of $H_s$ for $d=5$ [and the arrows are indicating the shuffled analysis]{}.[]{data-label=\"fig:ampgenre\"}](fig3.pdf)\n\n![Complexity-entropy causality plane for the intensity series by music genres when considering the original and shuffled series. The upper (bottom) dashed line represents the maximum (minimum) value of $C_{js}$ as a function of $H_s$ for $d=5$ [and the arrows are indicating the shuffled analysis]{}.[]{data-label=\"fig:intgenre\"}](fig4.pdf)\n\nTherefore, we have verified that the ordinal pattern distribution that exists among the sound amplitudes values and also among the sound intensity is capable to spread out our database songs though the complexity-entropy causality plane. It is interesting to remark that the embedding dimension employed here ($d=5$) corresponds to approximately $10^{-4}$ seconds. Thus, it is surprising how this very short time dynamics retains so much information about the songs. We also investigated shuffled version of each song series aiming to verify if the localization of the songs in the complexity-entropy causality plane is directly related to the presence of correlations in the music time series. This analysis is shown in Figs.\u00a0\\[fig:ampgenre\\] and \\[fig:intgenre\\] for each song and for all genres. We have obtained $H_s\\approx 1$ and $C_{js}\\approx 0$ for all shuffled series, confirming that correlations inherently present in the original songs are the main source for the different locations in this plane.\n\nAlthough our approach is not focused on determining which music genre is related to a particular given song, this novel physical method may help to understand the complex situation that emerges in the problem of automatic genre classification. For instance, we can take a glance on the fuzzy boundaries existent in the music genre definitions, by evaluating the distribution of $H_s$ and $C_{js}$ values. Figure \\[fig:pdfs\\] shows these distributions for both time series employed here. There are several overlapping regions among the distributions of $H_s$ and $C_{js}$ for the different genres. This overlapping is an illustration on how fuzzy the boundaries between genres and, consequently, the own concept of music genre can be. It is also interesting to observe that some genres have more localized PDFs, for instance, the techno genre is practically bounded to the interval $(0.85,0.95)$ of $H_s$ values for the intensity series while the flamenco or mpb genres have a wider distribution. [To go beyond the previous analysis, we try to quantify the efficiency of permutation indexes $H_s$ and $C_{js}$ in a practical scenery of automatic genre classification. In order to do this, we use an implementation\u00a0[@SVM1] of a support vector machine (SVM)\u00a0[@SVM2] where we have considered the values of $H_s$ and $C_{js}$ for the amplitudes and intensity series as features of the SVM. We run the analysis for each genre training the SVM with 90$\\%$ of dataset and performing an automatic detection over the remaining 10$\\%$. It is a simplified version of the SVM, where the system have to make a binary choice, i.e., to choose between a given genre and all the others. The accuracy rates of automatic detection are shown in Table \\[tab:SVM\\]. Note that the accuracy values are around 90$\\%$ within this simplified implementation, however we have to remark that in a multiple choice system these values should be much smaller. On the other hand, this analysis indicates that the entropic indexes employed here may be used in practical situations. ]{}\n\n[lrclr]{} Genre & Accuracy & & Genre & Accuracy\\\nBlues & 87.87$\\%$ & & Metal & 89.89$\\%$\\\nClassic & 92.03$\\%$ & & MPB & 97.15$\\%$\\\nFlamenco & 95.12$\\%$ & & Pop & 88.11$\\%$\\\nHiphop & 88.11$\\%$ & & Tango & 87.87$\\%$\\\nJazz & 91.68$\\%$ & & Techno & 87.14$\\%$\\\n\n![(color online) Probability distribution functions (PDF) for the values of (a) $H_s$ and (b) $C_{js}$ when considering the amplitude series grouped by music genre. Figs. (c) and (d) show the same PDFs for the intensity series.[]{data-label=\"fig:pdfs\"}](fig5.pdf)\n\nSummary and Conclusions\n=======================\n\nSumming up, in this work we applied the permutation entropy\u00a0[@Bandt], $H_s$, and an intensive statistical complexity measure\u00a0[@LopezRuiz; @Martin; @Lamberti], $C_{js}$, to differentiate songs. Specifically, we analyzed the location of the songs in the complexity-entropy causality plane. This permutation information theory approach enabled us to quantitatively classify songs in a kind of complexity hierarchy.\n\nWe believe that the findings presented here may be applied in practical situations as well as in technological applications related to the distinction of songs in massive databases. In this aspect, the Bandt and Pompe approach has some advantageous technical features, such as its simplicity, robustness, and principally a very fast numerical evaluation.\n\nAcknowledgements {#acknowledgements .unnumbered}\n================\n\n[The authors would like to thank an anonymous reviewer for his very helpful comments. Dr. Osvaldo A. Rosso is also acknowledged for useful discussions and valuable comments.]{} HVR, RSM and EKL are grateful to CNPq and CAPES (Brazilian agencies) for the financial support. HVR also thanks Angel A. Tateishi for the help with the music database and CAPES for financial support under the process No\u00a05678-11-0. LZ was supported by Consejo Nacional de Investigaciones Cient\u00edficas y T\u00e9cnicas (CONICET), Argentina.\n\n[99]{} F. Sebastiani, Acm. Comput. Surv. **34** (2002) 1. R. J. Radke, S. Andra, O. Al-Kofahi, B. Roysam, IEEE T. Image Process **14** (2005) 294. A. J. Enright, S. Van Dongen, C. A. Ouzounis, Nucleic. Acids Res. **30** (2002) 1575. S. Y. Auyang, *Foundations of complex-systems* (Cambridge University Press, Cambridge, 1998). H. J. Jensen, *Self-organized criticality* (Cambridge University Press, Cambridge, 1998). R. Albert, A.-L. Barab\u00e1si, Rev. Mod. Phys. **74** (2002) 47. D. Sornette, *Critical phenomena in natural sciences* (Springer-Verlag, Berlin, 2006). N. Boccara, *Modeling complex systems* (Springer-Verlag, Berlin, 2010). T. DeNora, *The music of everyday life* (Cambridge University Press, Cambridge, 2000). R. Lambiotte, M. Ausloos, Phys. Rev. E **72** (2005) 066107. R. Lambiotte, M. Ausloos, Eur. Phys. J. B **50** (2006) 183. J. M. Buld\u00fa, P. Cano, M. Koppenberger, J. A. Almendral, S. Boccaletti, New J. Phys. **9** (2007) 172. T. Teitelbaum, P. Balenzuela, P. Cano, J. M. Buld\u00fa, Chaos **18** (2008) 043105. R. Lambiotte, M. Ausloos, Physica A **362** (2006) 485. J. A. Davies, Eur. Phys. J. B **27** (2002) 445. E. P. Borges, Eur. Phys. J. B **30** (2002) 593. H.-B. Hu, D.-Y. Han, Physica A **387** (2008) 5916. R. F. Voss, J. Clarke, Nature **258** (1975) 317. Y. Klimontovich, J. P. Boon, Europhys. Lett. **3** (1987) 395. N. Nettheim, Journal of New Music Research **21** (1992) 135. K. J. Hs\u00fc, A. Hs\u00fc, Proc. Natl. Acad. Sci. USA **87** (1990) 938. K. J. Hs\u00fc, A. Hs\u00fc, Proc. Natl. Acad. Sci. USA **88** (1991) 3507. R. S. Mendes, H. V. Ribeiro, F. C. M. Freire, A. A. Tateishi, E. K. Lenzi, Phys. Rev. E **83** (2011) 017101. H. D. Jennings, P. Ch. Ivanov, A. M. Martins, P. C. da Silva, G. M. Viswanathan, Physica A **336** (2004) 585. D. C. Correa, J. H. Saito, L. F. Costa, New J. Phys. **12** (2010) 053030. J. P. Boon, O. Decroly, Chaos **5** (1995) 501. M. Bigerelle, A. Iost, Chaos Solitons Fractals **11** (2000) 2179. P. Diodati, S. Piazza, Eur. Phys. J. B **17** (2000) 143. G. G\u00fcnd\u00fcz, U. G\u00fcnd\u00fcs, Physica A **357** (2005) 565. Z.-Y. Su, T Wu, Physica D **221** (2006) 188. N. Scaringella, G. Zoia, D. Mlynek, IEEE Signal Process. Mag. **23** (2006) 133. G. R. Jafari, P. Pedram, L. Hedayatifar, J. Stat. Mech. (2007) P04012. L. Dagdug, J. Alvarez-Ramirez, C. Lopez, R. Moreno, E. Hernandez-Lemus, Physica A **383** (2007) 570. Z.-Y. Su, T Wu, Physica A **380** (2007) 418. M. Beltr\u00e1n del R\u00edo, G. Cocho, G. G. Naumis, Physica A **387** (2008) 5552. W. Ro, Y. Kwon, Chaos Solitons Fractals **42** (2009) 2305. J. Serr\u00e0, X. Serra, R. G. Andrzejak, New J. Phys. **11** (2009) 093017. M. M. Mostafa, N. Billor, Expert Syst. Appl. **36** (2009) 11378. J. P. Boon, Adv. Complex. Syst. **13** (2010) 155. G. Tzanetakis, P. Cook, IEEE Trans. Speech Audio Process. **20** (2002) 293. ISMIR - The International Society for Music Information Retrieval (http://www.ismir.net). T. Lidy, A. Rauber, In Proc. ISMIR, 2005. A. S. Lampropoulos, P. S. Lampropoulou, G. A. Tsihrintzis, In Proc. ISMIR, 2005. A. Meng, J. Shawe-Taylor, In Proc. ISMIR, 2005. E. Pampalk, A. Flexer, G. Widmer, In Proc. ISMIR, 2005. J. Reed, C.-H. Lee, In Proc. ISMIR, 2006. C. McKay, I. Fujinaga, In Proc. ISMIR, 2006. M. Dehghani, A. M. Lovett, In Proc. ISMIR, 2006. T. Lidy, A. Rauber, A. Pertusa, J. M. I\u00f1esta, In Proc. ISMIR, 2007. A. J. D. Craft, G. A. Wiggins, T. Crawford, In Proc. ISMIR, 2007. I. Panagakis, E. Benetos, C. Kotropoulos, In Proc. ISMIR, 2008. R. Mayer, R. Neumayer, A. Rauber, In Proc. ISMIR, 2008. R. Mayer, R. Neumayer, A. Rauber, In Proc. ISMIR, 2008. S. Doraisamy, S. Golzari, N. M. Norowi, Md. N. B. Sulaiman, N. I. Udzir, In Proc. ISMIR, 2008. C. Bandt, B. Pompe, Phys. Rev. Lett. **88** (2002) 174102. X. Li, G. Ouyang, D. A. Richards, Epilepsy Research **77** (2007) 70. N. Nicolaou, J. Georgiou, Clin. EEG Neurosci. **42** (2011) 24. L. Zunino, M. Zanin, B. M. Tabak, D. G. P\u00e9rez, O. A. Rosso, Physica A **389** (2010) 1891. L. Zunino, B. M. Tabak, F. Serinaldi, M. Zanin, D. G. P\u00e9rez, O. A. Rosso, Physica A **390** (2011) 876. P. M. Saco, L. C. Carpi, A. Figliola, E. Serrano, O. A. Rosso, Physica A **389** (2010) 5022. M. Barreiro, A. C. Marti, C. Masoller, Chaos **21** (2011) 013101. R. L\u00f3pez-Ruiz, H. L. Mancini, X. Calbet, Phys. Lett. A **209** (1995) 321. M. T. Martin, A. Plastino, O. A. Rosso, Phys. Lett. A **311** (2003) 126. P. W. Lamberti, M. T. Martin, A. Plastino, O. A. Rosso, Physica A **334** (2004) 119. O. A. Rosso, H. A. Larrondo, M. T. Martin, A. Plastino, M. A. Fuentes, Phys. Rev. Lett. **99** (2007) 154102. O. A. Rosso, L. Zunino, D. G. P\u00e9rez, A. Figliola, H. A. Larrondo, M. Garavaglia, M. T. Mart\u00edn, A. Plastino Phys. Rev. E **76** (2007) 061114. C. E. Shannon, Bell. Syst. Tech. J. **27** (1948) 623. M. T. Martin, A. Plastino, O. A. Rosso, Physica A **369** (2006) 439. L. Zunino, M. C. Soriano, I. Fischer, O. A. Rosso, C. R. Mirasso, Phys. Rev. E **82** (2010) 046212. M. C. Soriano, L. Zunino, O. A. Rosso, I. Fischer, C. R. Mirasso, IEEE J. Quantum Electron. **47** (2011) 252. L. Zunino, O. A. Rosso, M. C. Soriano, IEEE J. Sel. Top. Quantum Electron. **17** (2011) 1250. U. Parlitz, S. Berg, S. Luther, A. Schirdewan, J. Kurths, N. Wessel, Comput. Biol. Med. (2011), doi:10.1016/j.compbiomed.2011.03.017 (in press). T. Joachims, http://svmlight.joachims.org (accessed in November 2011). V. N. Vapnik, *The Nature of Statistical Learning Theory*. (Springer, New York, 1995).\n"
}