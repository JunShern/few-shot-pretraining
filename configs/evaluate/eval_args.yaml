# TODO: Merge this into the finetune config file
model: gpt2
model_args: null
tasks: null #[headqa, logiqa, mathqa, pubmedqa, qa4mre_2011, qa4mre_2012, qa4mre_2013] # prost, 
num_fewshot: 5
batch_size: 2
device: cuda:0
no_cache: False
limit: 50